---
sidebar_position: 1
sidebar_label: Start Here
---

# Welcome to LlamaFarm

LlamaFarm helps you ship retrieval-augmented and agentic AI apps from your laptop to production. It is fully open-source and intentionally extendableâ€”swap model providers, vector stores, parsers, and CLI workflows without rewriting your project.

## ðŸ“º Video Demo

**Quick Overview (90 seconds):** https://youtu.be/W7MHGyN0MdQ

Get a fast introduction to LlamaFarm's core features and see it in action.

## What You Can Do Today

- **Prototype locally** with Ollama or any OpenAI-compatible runtime (vLLM, Together, custom gateways).
- **Ingest and query documents** using configurable RAG pipelines defined entirely in YAML.
- **Choose your interface** â€“ Use the powerful `lf` CLI for automation and scripting, or the Designer web UI for visual project management with drag-and-drop dataset uploads and interactive configuration.
- **Extend everything** from model handlers to data processors by updating schemas and wiring your own implementations.

## Choose Your Own Adventure

| Get Started | Go Deeper | Build Your Own |
| ----------- | --------- | -------------- |
| [Quickstart](./quickstart/index.md) â€“ install, init, chat, ingest your first dataset. | [Core Concepts](./concepts/index.md) â€“ architecture, sessions, and components. | [Extending LlamaFarm](./extending/index.md) â€“ add runtimes, stores, parsers, and CLI commands. |
| [Designer Web UI](./designer/index.md) â€“ visual interface for project management. | [Configuration Guide](./configuration/index.md) â€“ schema-driven project settings. | [RAG Guide](./rag/index.md) â€“ strategies, processing pipelines, and monitoring. |
| [CLI Reference](./cli/index.md) â€“ command matrix and examples. | [Models & Runtime](./models/index.md) â€“ configure AI models and providers. | [Prompts](./prompts/index.md) â€“ prompt engineering and management. |

## Philosophy

- **Local-first, cloud-aware** â€“ everything works offline, yet you can point at remote runtimes when needed.
- **Configuration over code** â€“ projects are reproducible because behaviour lives in `llamafarm.yaml`.
- **Composable modules** â€“ RAG, prompts, and runtime selection work independently but integrate cleanly.
- **Flexible interfaces** â€“ Use the CLI for automation, the Designer for visual management, or the REST API for custom integrations.
- **Open for extension** â€“ documentation includes patterns for registering new providers, stores, and utilities.

:::tip Prefer Visual Tools?
The **Designer Web UI** provides a browser-based interface for managing projects, uploading datasets, and testing your AIâ€”all without touching the command line. It's automatically available at `http://localhost:7724` when you run `lf start` (or `http://localhost:3123` if using Docker Compose directly). [Learn more â†’](./designer/index.md)
:::

## ðŸŽ¥ In-Depth Tutorial

**Complete Walkthrough (7 minutes):** https://youtu.be/HNnZ4iaOSJ4

Watch a comprehensive demonstration of LlamaFarm's features including project setup, dataset ingestion, RAG queries, and configuration options.

---

Ready to build? Start with the [Quickstart](./quickstart/index.md) and keep the CLI open in another terminal.
