services:
  # ChromaDB Vector Database Server
  # Multi-process write conflicts by centralizing ChromaDB access
  # All RAG workers connect to this server instead of using separate persistent clients
  chromadb-server:
    image: chromadb/chroma:1.0.20
    ports:
      - "8001:8000"  # Expose on 8001 to avoid conflict with server
    environment:
      - PERSIST_DIRECTORY=/chroma/data
      - IS_PERSISTENT=TRUE
      - CHROMA_SERVER_HOST=0.0.0.0
      - CHROMA_SERVER_HTTP_PORT=8000
    volumes:
      - chromadb_data:/chroma/data
    healthcheck:
      test: ["CMD-SHELL", "timeout 5 bash -c '</dev/tcp/localhost/8000' || exit 1"]
      interval: 10s
      timeout: 10s
      retries: 5
      start_period: 60s
    restart: unless-stopped
    networks:
      - llamafarm
    labels:
      - "llamafarm.service=chromadb"
      - "llamafarm.issue=279"

  # FastAPI Backend Server (Lightweight - no RAG dependencies)
  server:
    image: ghcr.io/llama-farm/llamafarm/server:${IMAGE_TAG-latest}
    ports:
      - "8000:8000"
    environment:
      - PYTHONUNBUFFERED=1
      - LF_DATA_DIR=/var/lib/llamafarm
      - OLLAMA_HOST=http://host.docker.internal:11434
    volumes:
      - llamafarm_data:/var/lib/llamafarm
    extra_hosts:
      - "host.docker.internal:host-gateway"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health/liveness"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    restart: unless-stopped
    networks:
      - llamafarm

  # RAG Service (Separate container with RAG dependencies)
  rag:
    image: ghcr.io/llama-farm/llamafarm/rag:${IMAGE_TAG-latest}
    environment:
      - PYTHONUNBUFFERED=1
      - LF_DATA_DIR=/var/lib/llamafarm
      - OLLAMA_HOST=http://host.docker.internal:11434
      - CHROMADB_HOST=chromadb-server
      - CHROMADB_PORT=8000
    volumes:
      - llamafarm_data:/var/lib/llamafarm
    extra_hosts:
      - "host.docker.internal:host-gateway"
    depends_on:
      server:
        condition: service_healthy
      chromadb-server:
        condition: service_healthy
    healthcheck:
      test:
        ["CMD", "python", "-c", "import celery; print('RAG worker running')"]
      interval: 20s
      timeout: 15s
      retries: 5
      start_period: 90s
    restart: unless-stopped
    networks:
      - llamafarm

  # React Frontend Designer
  designer:
    image: ghcr.io/llama-farm/llamafarm/designer:${IMAGE_TAG-latest}
    ports:
      - "3123:80"
    environment:
      - VITE_APP_API_URL=http://server:8000
      - VITE_APP_ENV=production
    depends_on:
      server:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:80/"]
      interval: 15s
      timeout: 10s
      retries: 5
      start_period: 45s
    restart: unless-stopped
    networks:
      - llamafarm

networks:
  llamafarm:
    driver: bridge
    labels:
      - "llamafarm.managed=true"

volumes:
  llamafarm_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${HOME}/.llamafarm
    labels:
      - "llamafarm.managed=true"
  
  # ChromaDB persistent data volume
  # Stores vector embeddings and metadata to survive container restarts
  # Uses Docker-managed volume for better portability across environments
  chromadb_data:
    driver: local
    labels:
      - "llamafarm.managed=true"
      - "llamafarm.service=chromadb"
