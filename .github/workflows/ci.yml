name: CI

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

env:
  NX_NO_CLOUD: true

jobs:
  # Test Go CLI component
  test-cli:
    name: Test CLI (Go)
    runs-on: ubuntu-latest
    permissions:
      contents: read
      pull-requests: write
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Go
        uses: actions/setup-go@v5
        with:
          go-version: "1.24.4"
          cache-dependency-path: cli/go.sum

      - name: Cache Go modules
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/go-build
            ~/go/pkg/mod
          key: ${{ runner.os }}-go-${{ hashFiles('cli/go.sum') }}
          restore-keys: |
            ${{ runner.os }}-go-

      - name: Install dependencies
        working-directory: cli
        run: go mod download

      - name: Install uv
        uses: astral-sh/setup-uv@v4
        with:
          enable-cache: true
          cache-dependency-glob: "**/uv.lock"

      - name: Generate Python datamodels
        working-directory: config
        run: |
          echo "Generating datamodels from schema..."
          uv run python generate_types.py
          echo "✓ Datamodel generation complete"

      - name: Validate datamodel generation
        working-directory: config
        run: |
          if [ ! -f "datamodel.py" ] || [ ! -s "datamodel.py" ]; then
            echo "❌ Error: datamodel.py not generated or is empty"
            exit 1
          fi
          echo "✓ Datamodel validation passed"
          # Verify that compile_schema.py copied the dereferenced schema to cli/cmd/config
          if [ ! -f "../cli/cmd/config/schema.json" ]; then
            echo "❌ Error: schema.json not copied to cli/cmd/config by compile_schema.py"
            exit 1
          fi
          echo "✓ Dereferenced schema available at cli/cmd/config/schema.json"

      - name: Install go-jsonschema
        run: go install github.com/atombender/go-jsonschema@latest

      - name: Generate Go types
        run: |
          # Generate Go types from schema
          cd cli/cmd/config
          sh generate-types.sh
          echo "✓ Go types generation complete"

      - name: Build CLI
        working-directory: cli
        run: go build -v ./...

      - name: Run Go tests with coverage
        working-directory: cli
        run: |
          go test ./... -coverpkg=./... -covermode=atomic -coverprofile=coverage.out
          go tool cover -func=coverage.out | tee coverage.txt
          go build ./tools/cover2lcov
          ./cover2lcov -in coverage.out -out coverage.lcov
          go build ./tools/coverreport
          ./coverreport -in coverage.out -format=markdown > coverage.md

      - name: Run binary upgrade integration tests
        working-directory: cli
        run: |
          # Run Go-based integration tests
          go test -v -run TestUpgradeIntegration ./cmd/version/...

      - name: Publish CLI coverage to job summary
        run: |
          {
            echo '## CLI Coverage';
            echo;
            cat cli/coverage.md;
          } >> "$GITHUB_STEP_SUMMARY"

      - name: Upload CLI coverage artifact
        uses: actions/upload-artifact@v4
        with:
          name: cli-coverage
          path: |
            cli/coverage.out
            cli/coverage.txt

      # - name: Update PR description with CLI coverage
      #   if: github.event_name == 'pull_request' && github.event.pull_request.head.repo.fork == false
      #   uses: ./.github/actions/update-pr-coverage
      #   with:
      #     coverage_path: cli/coverage.md
      #     section_title: CLI Coverage
      #     start_marker: '<!-- CLI_COVERAGE_START -->'
      #     end_marker: '<!-- CLI_COVERAGE_END -->'

      # - name: Skipping PR description update (fork PR)
      #   if: github.event_name == 'pull_request' && github.event.pull_request.head.repo.fork == true
      #   run: |
      #     echo "PR is from a fork; cannot update PR description with GITHUB_TOKEN. Coverage is available in the job summary and as artifacts." >> "$GITHUB_STEP_SUMMARY"

  # Test Python components
  test-python:
    name: Test Python Components
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ["3.11", "3.12"]
        component: ["config", "rag", "server", "runtimes/universal"]
        exclude:
          # Server requires Python 3.12+
          - component: server
            python-version: "3.11"

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Install uv
        uses: astral-sh/setup-uv@v4
        with:
          enable-cache: true
          cache-dependency-glob: "**/uv.lock"

      - name: Generate Python datamodels (required for all components)
        working-directory: config
        run: |
          echo "Generating datamodels for ${{ matrix.component }} component tests..."
          uv run python generate_types.py
          echo "✓ Datamodel generation complete"

      - name: Verify datamodel was generated
        run: |
          echo "Checking for datamodel.py..."
          ls -lh config/datamodel.py || echo "❌ datamodel.py not found!"
          echo "Attempting import test..."
          cd config && python -c "from datamodel import LlamaFarmConfig; print('✓ Direct import successful')" || echo "❌ Direct import failed!"
          echo "Attempting module import test..."
          python -c "from config.datamodel import LlamaFarmConfig; print('✓ Module import successful')" || echo "❌ Module import failed!"

      - name: Check if component has tests
        id: check-tests
        working-directory: ${{ matrix.component }}
        run: |
          if [ -d "tests" ] || [ -f "test_*.py" ] || [ -f "*_test.py" ]; then
            echo "has_tests=true" >> $GITHUB_OUTPUT
          else
            echo "has_tests=false" >> $GITHUB_OUTPUT
          fi

      - name: Install dependencies
        working-directory: ${{ matrix.component }}
        env:
          # For universal runtime, use CPU-only PyTorch to avoid downloading 3GB+ of CUDA packages
          UV_EXTRA_INDEX_URL: ${{ matrix.component == 'runtimes/universal' && 'https://download.pytorch.org/whl/cpu' || '' }}
        run: |
          # For universal runtime, allow uv to search all indexes (PyTorch index has old versions of common packages)
          INDEX_STRATEGY_FLAG=""
          if [ "${{ matrix.component }}" = "runtimes/universal" ]; then
            INDEX_STRATEGY_FLAG="--index-strategy unsafe-best-match"
          fi
          
          if [ -f "uv.lock" ]; then
            # Install main + dev dependencies only (skip optional extras that may have platform requirements)
            # Use --frozen to avoid re-resolving dependencies from extras that aren't being installed
            uv sync --group dev --frozen $INDEX_STRATEGY_FLAG
          else
            echo "No uv.lock found, attempting to install from pyproject.toml"
            uv pip install -e . $INDEX_STRATEGY_FLAG
          fi

      - name: Install test dependencies
        if: steps.check-tests.outputs.has_tests == 'true'
        working-directory: ${{ matrix.component }}
        run: |
          # Install pytest if not already in dependencies
          uv add --dev pytest pytest-cov pytest-asyncio || true

      - name: Run linting
        working-directory: ${{ matrix.component }}
        run: |
          # Run ruff if available in project
          if uv run ruff --version 2>/dev/null; then
            uv run ruff check .
          else
            echo "Ruff not available, skipping linting"
          fi
        continue-on-error: false

      - name: Set up Ollama
        uses: pydantic/ollama-action@v3
        with:
          model: nomic-embed-text

      - name: Run tests
        if: steps.check-tests.outputs.has_tests == 'true'
        working-directory: ${{ matrix.component }}
        env:
          PYTHONPATH: ${{ github.workspace }}
        run: |
          uv run pytest -v --cov=. --cov-report=term-missing

      - name: Skip tests (no tests found)
        if: steps.check-tests.outputs.has_tests == 'false'
        run: |
          echo "No tests found for ${{ matrix.component }}, skipping test execution"
