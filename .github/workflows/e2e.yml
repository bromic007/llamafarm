name: End-to-End Tests
permissions:
  contents: read
  actions: read # Required to download artifacts from other workflows
  pull-requests: write # Can post PR comments
  statuses: write # Required to create commit status checks for fork PRs

on:
  # Trigger after CLI build completes (works for both main branch and PRs)
  workflow_run:
    workflows: ["Build CLI"]
    types: [completed]
  # Keep pull_request trigger for backward compatibility during transition
  # TODO: This can be removed once the workflow_run approach is verified working
  pull_request:
    branches: [main]
  # Also allow manual trigger
  workflow_dispatch:

env:
  NX_NO_CLOUD: true

jobs:
  e2e-test:
    name: E2E Tests (${{ matrix.os }})
    runs-on: ${{ matrix.os }}
    timeout-minutes: 45
    # Run for pull_request events directly, or for workflow_run events if CLI build succeeded
    if: |
      github.event_name == 'pull_request' ||
      (github.event_name == 'workflow_run' &&
       github.event.workflow_run.conclusion == 'success' &&
       (github.event.workflow_run.event == 'pull_request' ||
        github.event.workflow_run.head_branch == 'main' ||
        github.event.workflow_run.head_branch == 'develop'))
    strategy:
      fail-fast: false
      matrix:
        include:
          - os: ubuntu-latest
            artifact: llamafarm-linux-amd64
            binary: lf
          - os: macos-latest
            artifact: llamafarm-darwin-arm64
            binary: lf
          # - os: windows-latest
          #   artifact: llamafarm-windows-amd64.exe
          #   binary: lf.exe
    env:
      # Use the current branch/ref being tested instead of main
      LF_VERSION_REF: ${{ github.head_ref || github.ref_name }}
      # Use CPU-only PyTorch to avoid downloading 3GB+ of CUDA packages in CI
      UV_EXTRA_INDEX_URL: https://download.pytorch.org/whl/cpu
      # Allow uv to search all indexes for best version match (needed because PyTorch index
      # has old versions of common packages like 'requests' that would block resolution)
      UV_INDEX_STRATEGY: unsafe-best-match
      # Force CPU usage to avoid MPS issues on macOS runners
      TRANSFORMERS_FORCE_CPU: 1
      # Always use base repository for artifacts (cli.yml uploads to base repo)
      # This workflow runs on PRs (including forks), main/develop branches, and manual dispatch
      # Fork PRs are safe because workflow_run executes in the base repo context, not the fork
      ARTIFACT_REPO: ${{ github.repository }}

    steps:
      # ============================================================
      # Report Status Check (for workflow_run triggered by fork PRs)
      # Note: Direct pull_request events get status checks automatically
      # ============================================================
      - name: Set pending status check
        if: github.event_name == 'workflow_run' && github.event.workflow_run.event == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const sha = context.payload.workflow_run.head_sha;
            console.log(`Setting pending status for commit ${sha}`);
            await github.rest.repos.createCommitStatus({
              owner: context.repo.owner,
              repo: context.repo.repo,
              sha: sha,
              state: 'pending',
              context: 'E2E Tests / ${{ matrix.os }}',
              description: 'E2E tests are running...',
              target_url: `${process.env.GITHUB_SERVER_URL}/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId}`
            });
            console.log('✓ Pending status set');

      # ============================================================
      # Setup Phase
      # ============================================================
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          # For workflow_run, checkout the commit SHA that triggered the build
          # Use SHA instead of branch name to work with fork PRs
          ref: ${{ github.event.workflow_run.head_sha || github.sha }}

      # ============================================================
      # Download Pre-built CLI Binary
      # ============================================================
      - name: Wait for CLI build artifacts (PRs only)
        if: github.event_name == 'pull_request'
        id: wait-artifacts
        shell: bash
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          echo "Waiting for CLI build to produce artifacts..."
          COMMIT="${{ github.event.pull_request.head.sha }}"
          ARTIFACT_NAME="${{ matrix.artifact }}"
          MAX_WAIT=600  # 10 minutes
          ELAPSED=0

          while [ $ELAPSED -lt $MAX_WAIT ]; do
            echo "Checking for artifact (${ELAPSED}s elapsed)..."

            # Get artifact info including run ID
            ARTIFACT_INFO=$(gh api repos/${{ github.repository }}/actions/artifacts \
              --jq ".artifacts[] | select(.name == \"${ARTIFACT_NAME}\") | select(.workflow_run.head_sha == \"${COMMIT}\") | {id: .id, run_id: .workflow_run.id}" \
              2>/dev/null | head -n 1)

            if [ -n "$ARTIFACT_INFO" ]; then
              ARTIFACT_ID=$(echo "$ARTIFACT_INFO" | jq -r '.id')
              RUN_ID=$(echo "$ARTIFACT_INFO" | jq -r '.run_id')
              echo "✓ Artifact found! (ID: ${ARTIFACT_ID}, Run: ${RUN_ID})"
              echo "run_id=${RUN_ID}" >> $GITHUB_OUTPUT
              exit 0
            fi

            sleep 10
            ELAPSED=$((ELAPSED + 10))
          done

          echo "❌ Timeout waiting for artifact after ${MAX_WAIT}s"
          exit 1

      - name: Download CLI binary artifact (with run_id)
        if: github.event.workflow_run.id || steps.wait-artifacts.outputs.run_id
        uses: dawidd6/action-download-artifact@v6
        with:
          workflow: cli.yml
          run_id: ${{ github.event.workflow_run.id || steps.wait-artifacts.outputs.run_id }}
          name: ${{ matrix.artifact }}
          path: cli/
          if_no_artifact_found: fail

      - name: Download CLI binary artifact (search by commit)
        if: ${{ !(github.event.workflow_run.id || steps.wait-artifacts.outputs.run_id) }}
        uses: dawidd6/action-download-artifact@v6
        with:
          workflow: cli.yml
          commit: ${{ github.sha }}
          name: ${{ matrix.artifact }}
          path: cli/
          search_artifacts: true
          if_no_artifact_found: fail

      - name: Download PR info artifact
        if: github.event.workflow_run.id
        uses: dawidd6/action-download-artifact@v6
        with:
          workflow: cli.yml
          run_id: ${{ github.event.workflow_run.id }}
          name: pr-info
          path: ./pr-info
          if_no_artifact_found: ignore

      - name: Set PR info
        id: pr-info
        shell: bash
        env:
          EVENT_NAME: ${{ github.event_name }}
          PR_NUMBER_DIRECT: ${{ github.event.pull_request.number }}
          HEAD_SHA_DIRECT: ${{ github.event.pull_request.head.sha }}
        run: |
          # Handle direct pull_request events
          if [ "$EVENT_NAME" = "pull_request" ]; then
            echo "pr_number=${PR_NUMBER_DIRECT}" >> $GITHUB_OUTPUT
            echo "head_sha=${HEAD_SHA_DIRECT}" >> $GITHUB_OUTPUT
            echo "✓ PR metadata from pull_request event: PR #${PR_NUMBER_DIRECT}"
          # Handle workflow_run events (from pr-info artifact)
          elif [ -f ./pr-info/pr_number.txt ]; then
            # Read and trim whitespace from PR number
            PR_NUMBER=$(cat ./pr-info/pr_number.txt | tr -d '[:space:]')
            if [ -z "$PR_NUMBER" ] || [ "$PR_NUMBER" = "null" ]; then
              echo "⚠ Warning: Invalid PR number in metadata"
              echo "pr_number=" >> $GITHUB_OUTPUT
            else
              echo "pr_number=${PR_NUMBER}" >> $GITHUB_OUTPUT
              echo "head_sha=$(cat ./pr-info/head_sha.txt | tr -d '[:space:]')" >> $GITHUB_OUTPUT
              echo "base_sha=$(cat ./pr-info/base_sha.txt | tr -d '[:space:]')" >> $GITHUB_OUTPUT
              echo "head_ref=$(cat ./pr-info/head_ref.txt | tr -d '[:space:]')" >> $GITHUB_OUTPUT
              echo "head_repo=$(cat ./pr-info/head_repo.txt | tr -d '[:space:]')" >> $GITHUB_OUTPUT
              echo "base_repo=$(cat ./pr-info/base_repo.txt | tr -d '[:space:]')" >> $GITHUB_OUTPUT
              echo "✓ PR metadata loaded from artifact: PR #${PR_NUMBER}"
            fi
          else
            echo "pr_number=" >> $GITHUB_OUTPUT
            echo "No PR metadata found (this is a push, not a PR)"
          fi

      - name: Rename binary to standard name
        shell: bash
        run: |
          cd cli
          # The artifact contains the binary with the full artifact name
          # Rename it to the short name we want to use
          if [ -f "${{ matrix.artifact }}" ]; then
            mv "${{ matrix.artifact }}" "${{ matrix.binary }}"
            echo "✓ Renamed ${{ matrix.artifact }} to ${{ matrix.binary }}"
          else
            echo "Error: Downloaded artifact not found at cli/${{ matrix.artifact }}"
            ls -la
            exit 1
          fi

      - name: Make CLI binary executable
        if: runner.os != 'Windows'
        shell: bash
        run: chmod +x cli/${{ matrix.binary }}

      - name: Verify CLI binary works
        working-directory: cli
        shell: bash
        run: |
          ./${{ matrix.binary }} version
          echo "✓ CLI binary is functional"

      # ============================================================
      # Project Initialization
      # ============================================================
      - name: Create test directory
        shell: bash
        run: |
          TEST_DIR="${{ runner.temp }}/e2e-test"
          mkdir -p "$TEST_DIR"
          echo "TEST_DIR=$TEST_DIR" >> $GITHUB_ENV
          echo "✓ Test directory created at $TEST_DIR"

      - name: Initialize project with CLI
        working-directory: cli
        shell: bash
        run: |
          if ! ./${{ matrix.binary }} init --cwd "$TEST_DIR" --debug; then
            echo "❌ Project initialization failed, checking server health..."
            curl -s http://localhost:8000/health | jq '.' || echo "Server not reachable"
            exit 1
          fi
          echo "✓ Project initialized"

      - name: Verify project config was created
        shell: bash
        run: |
          if [ ! -f "$TEST_DIR/llamafarm.yaml" ]; then
            echo "❌ Error: llamafarm.yaml not created"
            exit 1
          fi
          echo "✓ Project configuration exists"
          echo ""
          echo "=== FULL CONFIG AFTER INIT ==="
          cat "$TEST_DIR/llamafarm.yaml"
          echo ""
          echo "=== Checking critical fields ==="
          echo "namespace: $(grep '^namespace:' "$TEST_DIR/llamafarm.yaml" || echo 'MISSING')"
          echo "name: $(grep '^name:' "$TEST_DIR/llamafarm.yaml" || echo 'MISSING')"
          echo "prompts.name: $(grep -A2 '^prompts:' "$TEST_DIR/llamafarm.yaml" | grep 'name:' | head -1 || echo 'MISSING')"

      - name: Switch to tiny models for fast CI testing
        shell: bash
        run: |
          echo "Switching to tiny models for faster CI execution..."
          # Install yq if not available
          if ! command -v yq &> /dev/null; then
            echo "Installing yq..."
            if [ "$RUNNER_OS" = "macOS" ]; then
              brew install yq
            else
              sudo wget -qO /usr/local/bin/yq https://github.com/mikefarah/yq/releases/latest/download/yq_linux_amd64
              sudo chmod +x /usr/local/bin/yq
            fi
          fi

          # Update runtime model and quantization
          yq -i '.runtime.models[0].model = "unsloth/Qwen3-0.6B-GGUF:IQ1_S"' "$TEST_DIR/llamafarm.yaml"

          # Update embedding model and dimension
          yq -i '.rag.databases[0].embedding_strategies[0].config.model = "sentence-transformers/all-MiniLM-L6-v2"' "$TEST_DIR/llamafarm.yaml"
          yq -i '.rag.databases[0].embedding_strategies[0].config.dimension = 384' "$TEST_DIR/llamafarm.yaml"

          echo "✓ Model configuration updated"
          echo ""
          echo "=== Updated runtime config ==="
          yq '.runtime.models[0]' "$TEST_DIR/llamafarm.yaml"
          echo ""
          echo "=== Updated embedding config ==="
          yq '.rag.databases[0].embedding_strategies[0].config | pick(["model", "dimension"])' "$TEST_DIR/llamafarm.yaml"

          # Verify the changes took effect
          RUNTIME_MODEL=$(yq '.runtime.models[0].model' "$TEST_DIR/llamafarm.yaml")
          if [ "$RUNTIME_MODEL" != "unsloth/Qwen3-0.6B-GGUF:IQ1_S" ]; then
            echo "❌ Model configuration update failed!"
            echo "Expected: unsloth/Qwen3-0.6B-GGUF:IQ1_S"
            echo "Got: $RUNTIME_MODEL"
            exit 1
          fi
          echo "✓ Model configuration verified"

      - name: Pre-warm models by loading them
        working-directory: cli
        shell: bash
        timeout-minutes: 8
        env:
          PYTHONUNBUFFERED: "1"
          HF_HUB_ENABLE_HF_TRANSFER: "1" # Use faster download method
        run: |
          echo "Pre-warming models (downloading and loading)..."
          echo "Model: unsloth/Qwen3-0.6B-GGUF (IQ1_S quantization)"
          echo "Expected size: ~50-100MB"
          echo ""

          # Use a simple query to trigger model loading
          # The --no-rag flag means we only need to load the language model, not embeddings yet
          START_TIME=$(date +%s)
          if ./${{ matrix.binary }} --cwd "$TEST_DIR" --debug chat --no-rag "hi" 2>&1 | tee /tmp/prewarm.log; then
            END_TIME=$(date +%s)
            DURATION=$((END_TIME - START_TIME))
            echo ""
            echo "✓ Models successfully pre-warmed in ${DURATION}s"
          else
            echo ""
            echo "❌ Model pre-warming failed!"
            echo "Checking server health..."
            curl -s http://localhost:8000/health | jq '.' || echo "Server not reachable"
            echo ""
            echo "Last 50 lines of output:"
            tail -50 /tmp/prewarm.log
            exit 1
          fi

      # ============================================================
      # Data Ingestion Test
      # ============================================================
      - name: Create dataset
        working-directory: cli
        shell: bash
        env:
          PYTHONUNBUFFERED: "1"
        run: |
          if ! ./${{ matrix.binary }} --cwd "$TEST_DIR" --debug datasets create \
            -s universal_processor \
            -b main_database \
            test_dataset; then
            echo "❌ Dataset creation failed, checking server health..."
            curl -s http://localhost:8000/health | jq '.' || echo "Server not reachable"
            exit 1
          fi
          echo "✓ Dataset created"

      - name: Wait for config sync after dataset create
        shell: bash
        run: sleep 2.5

      - name: Debug config after dataset create
        shell: bash
        run: |
          echo ""
          echo "=== Config after dataset create (first 40 lines) ==="
          head -40 "$TEST_DIR/llamafarm.yaml"
          echo ""
          echo "=== Checking critical fields ==="
          echo "namespace: $(grep '^namespace:' "$TEST_DIR/llamafarm.yaml" || echo 'MISSING')"
          echo "name: $(grep '^name:' "$TEST_DIR/llamafarm.yaml" || echo 'MISSING')"
          echo "prompts.name: $(grep -A2 '^prompts:' "$TEST_DIR/llamafarm.yaml" | grep 'name:' | head -1 || echo 'MISSING')"
          echo "datasets: $(grep -A5 '^datasets:' "$TEST_DIR/llamafarm.yaml" | head -6)"

      - name: Upload sample files
        working-directory: cli
        shell: bash
        env:
          PYTHONUNBUFFERED: "1"
        run: |
          if ! ./${{ matrix.binary }} --cwd "$TEST_DIR" --debug datasets upload test_dataset "../examples/quick_rag/files"; then
            echo "❌ Upload failed for ../examples/quick_rag/files, checking server health..."
            echo "Current directory: $(pwd)"
            curl -s http://localhost:8000/health | jq '.' || echo "Server not reachable"
            exit 1
          fi
          echo "✓ All sample files uploaded"

      - name: Wait for config sync after dataset upload
        shell: bash
        run: sleep 2.5

      - name: Debug config before dataset process
        shell: bash
        run: |
          echo ""
          echo "=== Config before dataset process ==="
          echo "File exists: $(test -f "$TEST_DIR/llamafarm.yaml" && echo 'YES' || echo 'NO')"
          if [ -f "$TEST_DIR/llamafarm.yaml" ]; then
            echo "File size: $(wc -c < "$TEST_DIR/llamafarm.yaml")"
          else
            echo "File size: N/A"
          fi
          echo ""
          echo "=== Full config content ==="
          cat "$TEST_DIR/llamafarm.yaml" || echo "Failed to read config"
          echo ""
          echo "=== Critical fields check ==="
          echo "namespace: $(grep '^namespace:' "$TEST_DIR/llamafarm.yaml" || echo 'MISSING')"
          echo "name: $(grep '^name:' "$TEST_DIR/llamafarm.yaml" || echo 'MISSING')"
          echo "prompts.name: $(grep -A2 '^prompts:' "$TEST_DIR/llamafarm.yaml" | grep 'name:' | head -1 || echo 'MISSING')"

      - name: Process dataset
        working-directory: cli
        shell: bash
        env:
          PYTHONUNBUFFERED: "1"
        run: |
          sleep 2
          if ! ./${{ matrix.binary }} --cwd "$TEST_DIR" --debug datasets process test_dataset; then
            echo "❌ Dataset processing failed, checking server health..."
            curl -s http://localhost:8000/health | jq '.' || echo "Server not reachable"
            exit 1
          fi
          echo "✓ Dataset processing complete"

      # ============================================================
      # RAG Query Test
      # ============================================================
      - name: Run RAG query
        working-directory: cli
        shell: bash
        env:
          PYTHONUNBUFFERED: "1"
        run: |
          echo "Running RAG query..."
          if ! OUTPUT=$(./${{ matrix.binary }} --cwd "$TEST_DIR" --debug rag query \
            --database main_database \
            --top-k 3 \
            "neural scaling laws" 2>&1); then
            echo "❌ RAG query command failed"
            echo "$OUTPUT"
            echo "Checking server health..."
            curl -s http://localhost:8000/health | jq '.' || echo "Server not reachable"
            exit 1
          fi

          echo "$OUTPUT"

          # Verify output is not empty
          if [ -z "$OUTPUT" ]; then
            echo "❌ Error: RAG query returned empty output"
            curl -s http://localhost:8000/health | jq '.' || echo "Server not reachable"
            exit 1
          fi

          echo "✓ RAG query returned results"

      - name: Validate RAG query results
        working-directory: cli
        shell: bash
        env:
          PYTHONUNBUFFERED: "1"
        run: |
          if ! OUTPUT=$(./${{ matrix.binary }} --cwd "$TEST_DIR" --debug rag query \
            --database main_database \
            --top-k 3 \
            --include-metadata \
            "neural scaling laws" 2>&1); then
            echo "❌ RAG query validation failed"
            echo "$OUTPUT"
            echo "Checking server health..."
            curl -s http://localhost:8000/health | jq '.' || echo "Server not reachable"
            exit 1
          fi

          # Check if output contains expected content
          if echo "$OUTPUT" | grep -q "neural"; then
            echo "✓ RAG query results contain relevant content"
          else
            echo "⚠ Warning: Results may not contain expected content"
            echo "$OUTPUT"
          fi

      # ============================================================
      # Chat Command Test
      # ============================================================
      - name: Run chat command with RAG
        working-directory: cli
        shell: bash
        env:
          PYTHONUNBUFFERED: "1"
        run: |
          echo "Running chat command with RAG..."
          if ! OUTPUT=$(./${{ matrix.binary }} --cwd "$TEST_DIR" --debug chat \
            "Summarize neural scaling laws in one sentence" 2>&1); then
            echo "❌ Chat command failed"
            echo "$OUTPUT"
            echo "Checking server health..."
            curl -s http://localhost:8000/health | jq '.' || echo "Server not reachable"
            exit 1
          fi

          echo "Chat response:"
          echo "$OUTPUT"

          # Verify output is not empty
          if [ -z "$OUTPUT" ]; then
            echo "❌ Error: Chat command returned empty output"
            curl -s http://localhost:8000/health | jq '.' || echo "Server not reachable"
            exit 1
          fi

          # Check if output contains some text (at least 10 characters)
          if [ ${#OUTPUT} -lt 10 ]; then
            echo "❌ Error: Chat response too short, possible error"
            curl -s http://localhost:8000/health | jq '.' || echo "Server not reachable"
            exit 1
          fi

          echo "✓ Chat command returned a response"

      - name: Test chat command without RAG
        working-directory: cli
        shell: bash
        env:
          PYTHONUNBUFFERED: "1"
        run: |
          echo "Running chat command without RAG..."
          if ! OUTPUT=$(./${{ matrix.binary }} --cwd "$TEST_DIR" --debug chat \
            --no-rag \
            "What is 2 + 2?" 2>&1); then
            echo "❌ Chat command (no RAG) failed"
            echo "$OUTPUT"
            echo "Checking server health..."
            curl -s http://localhost:8000/health | jq '.' || echo "Server not reachable"
            exit 1
          fi

          echo "Chat response:"
          echo "$OUTPUT"

          # Verify output is not empty
          if [ -z "$OUTPUT" ]; then
            echo "❌ Error: Chat command (no RAG) returned empty output"
            curl -s http://localhost:8000/health | jq '.' || echo "Server not reachable"
            exit 1
          fi

          echo "✓ Chat command without RAG works"

      # ============================================================
      # Validation & Summary
      # ============================================================
      - name: List datasets to verify persistence
        working-directory: cli
        shell: bash
        env:
          PYTHONUNBUFFERED: "1"
        run: |
          echo "Listing datasets..."
          if ! ./${{ matrix.binary }} --cwd "$TEST_DIR" --debug datasets list; then
            echo "❌ Dataset listing failed, checking server health..."
            curl -s http://localhost:8000/health | jq '.' || echo "Server not reachable"
            exit 1
          fi
          echo "✓ Dataset listing works"

      - name: Check RAG health
        working-directory: cli
        shell: bash
        env:
          PYTHONUNBUFFERED: "1"
        run: |
          echo "Checking RAG health..."
          ./${{ matrix.binary }} --cwd "$TEST_DIR" --debug rag health || true
          echo "✓ RAG health check complete"

      - name: E2E test summary
        shell: bash
        run: |
          echo "=========================================="
          echo "End-to-End Test Summary (${{ matrix.os }})"
          echo "=========================================="
          echo "✓ CLI binary downloaded and verified"
          echo "✓ Project initialized"
          echo "✓ Dataset created and processed"
          echo "✓ RAG queries executed"
          echo "✓ Chat commands completed"
          echo "=========================================="
          echo "All E2E tests passed!"

      # ============================================================
      # Cleanup
      # ============================================================
      - name: Cleanup test artifacts
        if: always()
        shell: bash
        run: |
          echo "Cleaning up test directory..."
          rm -rf "$TEST_DIR"
          echo "✓ Cleanup complete"

      # ============================================================
      # Report Final Status Check (for fork PRs visibility)
      # ============================================================
      - name: Report final status check
        if: always() && github.event_name == 'workflow_run' && github.event.workflow_run.event == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const sha = context.payload.workflow_run.head_sha;
            const jobStatus = '${{ job.status }}';
            const state = jobStatus === 'success' ? 'success' : 'failure';
            const description = state === 'success' 
              ? 'All E2E tests passed!' 
              : `E2E tests ${jobStatus}`;
            
            console.log(`Setting ${state} status for commit ${sha}`);
            await github.rest.repos.createCommitStatus({
              owner: context.repo.owner,
              repo: context.repo.repo,
              sha: sha,
              state: state,
              context: 'E2E Tests / ${{ matrix.os }}',
              description: description,
              target_url: `${process.env.GITHUB_SERVER_URL}/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId}`
            });
            console.log(`✓ Final status (${state}) reported`);

      - name: Display service logs on failure
        if: failure()
        shell: bash
        run: |
          echo "=========================================="
          echo "Service Logs (${{ matrix.os }})"
          echo "=========================================="

          # Determine home directory (cross-platform)
          if [ "$RUNNER_OS" = "Windows" ]; then
            LF_HOME="$USERPROFILE/.llamafarm"
          else
            LF_HOME="$HOME/.llamafarm"
          fi

          # Display server logs if they exist
          if [ -f "$LF_HOME/logs/server.log" ]; then
            echo "--- Server Logs ---"
            tail -100 "$LF_HOME/logs/server.log"
          else
            echo "No server logs found at $LF_HOME/logs/server.log"
          fi

          echo ""

          # Display RAG logs if they exist
          if [ -f "$LF_HOME/logs/rag.log" ]; then
            echo "--- RAG Worker Logs ---"
            tail -100 "$LF_HOME/logs/rag.log"
          else
            echo "No RAG logs found at $LF_HOME/logs/rag.log"
          fi

          echo ""

          # Display Universal Runtime logs if they exist
          if [ -f "$LF_HOME/logs/universal-runtime.log" ]; then
            echo "--- Universal Runtime Logs ---"
            tail -100 "$LF_HOME/logs/universal-runtime.log"
          else
            echo "No Universal Runtime logs found at $LF_HOME/logs/universal-runtime.log"
          fi

      - name: Upload logs on failure
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: e2e-test-logs-${{ matrix.os }}
          path: ~/.llamafarm/logs/
          retention-days: 7
          if-no-files-found: warn

      # ============================================================
      # Post PR Comment with Results
      # ============================================================
      - name: Build test results summary
        if: always() && steps.pr-info.outputs.pr_number != ''
        id: build-summary
        shell: bash
        env:
          HEAD_SHA: ${{ steps.pr-info.outputs.head_sha }}
        run: |
          CONCLUSION="${{ job.status }}"
          WORKFLOW_RUN_URL="${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
          
          # Determine status emoji and message
          if [ "$CONCLUSION" = "success" ]; then
            STATUS_EMOJI="✅"
            STATUS_TEXT="**All E2E tests passed!**"
          elif [ "$CONCLUSION" = "failure" ]; then
            STATUS_EMOJI="❌"
            STATUS_TEXT="**E2E tests failed**"
          elif [ "$CONCLUSION" = "cancelled" ]; then
            STATUS_EMOJI="⚠️"
            STATUS_TEXT="**E2E tests were cancelled**"
          else
            STATUS_EMOJI="❓"
            STATUS_TEXT="**E2E tests completed with status: ${CONCLUSION}**"
          fi
          
          # Build the comment body and save to file
          {
            echo "${STATUS_EMOJI} ${STATUS_TEXT} (${{ matrix.os }})"
            echo ""
            echo "### Test Results Summary"
            echo ""
            echo "- **Workflow Run**: [View Details](${WORKFLOW_RUN_URL})"
            echo "- **Commit**: \`${HEAD_SHA:0:7}\`"
            echo "- **Status**: \`${CONCLUSION}\`"
            echo "- **OS**: \`${{ matrix.os }}\`"
            echo ""
            echo "---"
            echo "*This comment was automatically generated by the E2E Tests workflow.*"
          } > comment-body-${{ matrix.os }}.txt
          echo "Comment body prepared for ${{ matrix.os }}"

      - name: Find existing comment
        if: always() && steps.pr-info.outputs.pr_number != ''
        id: find-comment
        uses: actions/github-script@v7
        env:
          PR_NUMBER: ${{ steps.pr-info.outputs.pr_number }}
        with:
          script: |
            const prNumber = process.env.PR_NUMBER;
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: prNumber,
            });
            
            // Find comment from this bot (contains the marker)
            const botComment = comments.find(comment => 
              comment.user.type === 'Bot' && 
              comment.body.includes('*This comment was automatically generated by the E2E Tests workflow.*')
            );
            
            if (botComment) {
              core.setOutput('comment_id', botComment.id);
              core.setOutput('exists', 'true');
              console.log(`Found existing comment: ${botComment.id}`);
            } else {
              core.setOutput('exists', 'false');
              console.log('No existing comment found');
            }

      - name: Post or update PR comment
        if: always() && steps.pr-info.outputs.pr_number != ''
        uses: actions/github-script@v7
        env:
          PR_NUMBER: ${{ steps.pr-info.outputs.pr_number }}
          OS: ${{ matrix.os }}
        with:
          script: |
            const fs = require('fs');
            const prNumber = process.env.PR_NUMBER;
            const os = process.env.OS;
            const commentFile = `comment-body-${os}.txt`;
            
            if (!fs.existsSync(commentFile)) {
              console.log(`Comment file not found: ${commentFile}`);
              return;
            }
            
            const newCommentBody = fs.readFileSync(commentFile, 'utf8');
            const commentExists = '${{ steps.find-comment.outputs.exists }}' === 'true';
            const existingCommentId = '${{ steps.find-comment.outputs.comment_id }}';
            
            if (commentExists && existingCommentId) {
              // Get existing comment and append new results
              const { data: existingComment } = await github.rest.issues.getComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: existingCommentId,
              });
              
              // Append new OS results to existing comment
              const updatedBody = existingComment.body + '\n\n---\n\n' + newCommentBody;
              
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: existingCommentId,
                body: updatedBody
              });
              console.log(`✅ Updated existing comment #${existingCommentId} on PR #${prNumber} with ${os} results`);
            } else {
              // Create new comment
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: prNumber,
                body: newCommentBody
              });
              console.log(`✅ Created new comment on PR #${prNumber} for ${os}`);
            }

  # Handle CLI build failures
  notify-cli-failure:
    name: Notify CLI Build Failure
    runs-on: ubuntu-latest
    if: github.event.workflow_run.conclusion == 'failure'
    permissions:
      contents: read
      pull-requests: write
      actions: read
      statuses: write # Required to report failure status for fork PRs
    steps:
      - name: Download PR info artifact
        uses: dawidd6/action-download-artifact@v6
        with:
          workflow: cli.yml
          run_id: ${{ github.event.workflow_run.id }}
          name: pr-info
          path: ./pr-info
          if_no_artifact_found: ignore

      - name: Set PR info
        id: pr-info
        shell: bash
        run: |
          if [ -f ./pr-info/pr_number.txt ]; then
            # Read and trim whitespace from PR number
            PR_NUMBER=$(cat ./pr-info/pr_number.txt | tr -d '[:space:]')
            if [ -z "$PR_NUMBER" ] || [ "$PR_NUMBER" = "null" ]; then
              echo "⚠ Warning: Invalid PR number in metadata"
              echo "pr_number=" >> $GITHUB_OUTPUT
            else
              echo "pr_number=${PR_NUMBER}" >> $GITHUB_OUTPUT
              echo "✓ PR metadata loaded: PR #${PR_NUMBER}"
            fi
          else
            echo "pr_number=" >> $GITHUB_OUTPUT
            echo "No PR metadata found (this is a push, not a PR)"
          fi

      - name: Comment on PR about CLI build failure
        if: steps.pr-info.outputs.pr_number != ''
        uses: actions/github-script@v7
        env:
          PR_NUMBER: ${{ steps.pr-info.outputs.pr_number }}
        with:
          script: |
            const prNumber = process.env.PR_NUMBER;
            const workflowRunUrl = context.payload.workflow_run.html_url;
            
            const commentBody = [
              '⚠️ **CLI build failed** - E2E tests were not run.',
              '',
              `Check the [CLI build workflow run](${workflowRunUrl}) for details.`,
              '',
              '---',
              '*This comment was automatically generated by the E2E Tests workflow.*'
            ].join('\n');
            
            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: prNumber,
              body: commentBody
            });
            console.log(`✅ Posted CLI build failure comment on PR #${prNumber}`);

      - name: Report CLI build failure status
        if: github.event.workflow_run.event == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const sha = context.payload.workflow_run.head_sha;
            console.log(`Setting failure status for commit ${sha} (CLI build failed)`);
            
            // Report failure for both matrix entries that would have run
            const osTargets = ['ubuntu-latest', 'macos-latest'];
            for (const os of osTargets) {
              await github.rest.repos.createCommitStatus({
                owner: context.repo.owner,
                repo: context.repo.repo,
                sha: sha,
                state: 'failure',
                context: `E2E Tests / ${os}`,
                description: 'CLI build failed - E2E tests skipped',
                target_url: context.payload.workflow_run.html_url
              });
            }
            console.log('✓ Failure status reported for all E2E test contexts');
