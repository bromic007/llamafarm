name: End-to-End Tests
permissions:
  contents: read
  actions: read # Required to download artifacts and check workflow status
  pull-requests: write # Can post PR comments (only works for non-fork PRs)

on:
  push:
    branches: [main]
  pull_request:
    types: [opened, synchronize, reopened]
    branches: [main]
  # Allow manual trigger for debugging
  workflow_dispatch:

env:
  NX_NO_CLOUD: true

jobs:
  # ============================================================
  # Notify PR that E2E tests are starting
  # Note: This job is skipped for fork PRs due to GitHub's security model
  # which limits GITHUB_TOKEN to read-only for workflows triggered by forks.
  # ============================================================
  notify-start:
    name: Notify E2E Starting
    # Only run for non-fork PRs (fork PRs have head.repo.fork = true)
    if: github.event_name == 'pull_request' && github.event.pull_request.head.repo.fork == false
    runs-on: ubuntu-latest
    steps:
      - name: Get PR info
        id: pr-info
        run: |
          echo "pr_number=${{ github.event.pull_request.number }}" >> $GITHUB_OUTPUT
          echo "head_sha=${{ github.event.pull_request.head.sha }}" >> $GITHUB_OUTPUT

      - name: Build in-progress comment
        env:
          HEAD_SHA: ${{ steps.pr-info.outputs.head_sha }}
        run: |
          WORKFLOW_RUN_URL="${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"

          {
            echo "## :hourglass_flowing_sand: **E2E Tests Running...**"
            echo ""
            echo "### Test Results by Platform"
            echo ""
            echo "| OS | Status |"
            echo "|---|---|"
            echo "| ubuntu-latest | :hourglass: Pending |"
            echo "| macos-latest | :hourglass: Pending |"
            echo "| windows-latest | :hourglass: Pending |"
            echo ""
            echo "### Summary"
            echo ""
            echo "- **Status**: Tests in progress..."
            echo "- **Workflow Run**: [View Details](${WORKFLOW_RUN_URL})"
            echo "- **Commit**: \`${HEAD_SHA:0:7}\`"
            echo ""
            echo "---"
            echo "*This comment was automatically generated by the E2E Tests workflow.*"
          } > comment-body.txt

          echo "Comment body prepared:"
          cat comment-body.txt

      - name: Find existing comment
        id: find-comment
        uses: actions/github-script@v7
        env:
          PR_NUMBER: ${{ steps.pr-info.outputs.pr_number }}
        with:
          script: |
            const prNumber = process.env.PR_NUMBER;
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: prNumber,
            });

            // Find comment from this bot (contains the marker)
            const botComment = comments.find(comment =>
              comment.user.type === 'Bot' &&
              comment.body.includes('*This comment was automatically generated by the E2E Tests workflow.*')
            );

            if (botComment) {
              core.setOutput('comment_id', botComment.id);
              core.setOutput('exists', 'true');
              console.log(`Found existing comment: ${botComment.id}`);
            } else {
              core.setOutput('exists', 'false');
              console.log('No existing comment found');
            }

      - name: Post or update PR comment
        uses: actions/github-script@v7
        env:
          PR_NUMBER: ${{ steps.pr-info.outputs.pr_number }}
        with:
          retries: 3
          script: |
            const fs = require('fs');
            const prNumber = process.env.PR_NUMBER;

            if (!fs.existsSync('comment-body.txt')) {
              console.log('Comment file not found');
              return;
            }

            const commentBody = fs.readFileSync('comment-body.txt', 'utf8');
            const commentExists = '${{ steps.find-comment.outputs.exists }}' === 'true';
            const existingCommentId = '${{ steps.find-comment.outputs.comment_id }}';

            if (commentExists && existingCommentId) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: existingCommentId,
                body: commentBody
              });
              console.log(`Updated existing comment #${existingCommentId} on PR #${prNumber}`);
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: prNumber,
                body: commentBody
              });
              console.log(`Created new comment on PR #${prNumber}`);
            }

  wait-for-cli:
    name: Wait for CLI Build
    runs-on: ubuntu-latest
    outputs:
      cli_run_id: ${{ steps.wait.outputs.run_id }}
    steps:
      - name: Wait for CLI workflow to complete
        id: wait
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          echo "Waiting for 'Build CLI' workflow to complete..."

          # Get the current commit SHA
          if [ "${{ github.event_name }}" = "pull_request" ]; then
            COMMIT_SHA="${{ github.event.pull_request.head.sha }}"
          else
            COMMIT_SHA="${{ github.sha }}"
          fi
          echo "Looking for CLI build for commit: $COMMIT_SHA"

          # Wait up to 15 minutes for the CLI workflow to complete
          MAX_ATTEMPTS=30
          SLEEP_TIME=30

          for i in $(seq 1 $MAX_ATTEMPTS); do
            echo "Attempt $i/$MAX_ATTEMPTS: Checking CLI workflow status..."

            # Find the CLI workflow run for this commit
            RUN_INFO=$(gh api \
              -H "Accept: application/vnd.github+json" \
              "/repos/${{ github.repository }}/actions/workflows/cli.yml/runs?head_sha=$COMMIT_SHA&per_page=1" \
              --jq '.workflow_runs[0] | {id: .id, status: .status, conclusion: .conclusion}' 2>/dev/null || echo "{}")

            RUN_ID=$(echo "$RUN_INFO" | jq -r '.id // empty')
            STATUS=$(echo "$RUN_INFO" | jq -r '.status // empty')
            CONCLUSION=$(echo "$RUN_INFO" | jq -r '.conclusion // empty')

            if [ -z "$RUN_ID" ]; then
              echo "  No CLI workflow run found yet, waiting..."
              sleep $SLEEP_TIME
              continue
            fi

            echo "  Found run $RUN_ID: status=$STATUS, conclusion=$CONCLUSION"

            if [ "$STATUS" = "completed" ]; then
              if [ "$CONCLUSION" = "success" ]; then
                echo "✓ CLI workflow completed successfully!"
                echo "run_id=$RUN_ID" >> $GITHUB_OUTPUT
                exit 0
              else
                echo "❌ CLI workflow failed with conclusion: $CONCLUSION"
                exit 1
              fi
            fi

            echo "  Workflow still running, waiting ${SLEEP_TIME}s..."
            sleep $SLEEP_TIME
          done

          echo "❌ Timed out waiting for CLI workflow"
          exit 1

  e2e-test:
    name: E2E Tests (${{ matrix.os }})
    needs: wait-for-cli
    runs-on: ${{ matrix.os }}
    timeout-minutes: 45
    strategy:
      fail-fast: false
      matrix:
        include:
          - os: ubuntu-latest
            artifact: llamafarm-linux-amd64
            binary: lf
          - os: macos-latest
            artifact: llamafarm-darwin-arm64
            binary: lf
          - os: windows-latest
            artifact: llamafarm-windows-amd64.exe
            binary: lf.exe
    env:
      # Use the current branch/ref being tested instead of main
      # For PRs (including fork PRs), use the merge ref which is always accessible
      # For pushes to main, use the branch name directly
      LF_VERSION_REF: ${{ github.event_name == 'pull_request' && format('refs/pull/{0}/merge', github.event.pull_request.number) || github.ref_name }}
      # Use CPU-only PyTorch to avoid downloading 3GB+ of CUDA packages in CI
      UV_EXTRA_INDEX_URL: https://download.pytorch.org/whl/cpu
      # Allow uv to search all indexes for best version match (needed because PyTorch index
      # has old versions of common packages like 'requests' that would block resolution)
      UV_INDEX_STRATEGY: unsafe-best-match
      # Force CPU usage to avoid MPS issues on macOS runners
      TRANSFORMERS_FORCE_CPU: 1

    steps:
      # ============================================================
      # Setup Phase
      # ============================================================
      - name: Checkout code
        uses: actions/checkout@v4

      # ============================================================
      # Download Pre-built CLI Binary
      # ============================================================
      - name: Download CLI binary artifact
        uses: dawidd6/action-download-artifact@v6
        with:
          workflow: cli.yml
          run_id: ${{ needs.wait-for-cli.outputs.cli_run_id }}
          name: ${{ matrix.artifact }}
          path: cli/
          if_no_artifact_found: fail

      - name: Download PR info artifact
        if: github.event_name == 'pull_request'
        uses: dawidd6/action-download-artifact@v6
        with:
          workflow: cli.yml
          run_id: ${{ needs.wait-for-cli.outputs.cli_run_id }}
          name: pr-info
          path: ./pr-info
          if_no_artifact_found: ignore

      - name: Set PR info
        id: pr-info
        shell: bash
        run: |
          # For PRs, use the PR number directly from the event
          if [ "${{ github.event_name }}" = "pull_request" ]; then
            echo "pr_number=${{ github.event.pull_request.number }}" >> $GITHUB_OUTPUT
            echo "head_sha=${{ github.event.pull_request.head.sha }}" >> $GITHUB_OUTPUT
            echo "✓ PR metadata from event: PR #${{ github.event.pull_request.number }}"
          else
            echo "pr_number=" >> $GITHUB_OUTPUT
            echo "Not a PR event"
          fi

      - name: Rename binary to standard name
        shell: bash
        run: |
          cd cli
          # The artifact contains the binary with the full artifact name
          # Rename it to the short name we want to use
          if [ -f "${{ matrix.artifact }}" ]; then
            mv "${{ matrix.artifact }}" "${{ matrix.binary }}"
            echo "✓ Renamed ${{ matrix.artifact }} to ${{ matrix.binary }}"
          else
            echo "Error: Downloaded artifact not found at cli/${{ matrix.artifact }}"
            ls -la
            exit 1
          fi

      - name: Make CLI binary executable
        if: runner.os != 'Windows'
        shell: bash
        run: chmod +x cli/${{ matrix.binary }}

      - name: Verify CLI binary works
        working-directory: cli
        shell: bash
        run: |
          ./${{ matrix.binary }} version
          echo "✓ CLI binary is functional"

      # ============================================================
      # Project Initialization
      # ============================================================
      - name: Create test directory
        shell: bash
        run: |
          TEST_DIR="${{ runner.temp }}/e2e-test"
          mkdir -p "$TEST_DIR"
          echo "TEST_DIR=$TEST_DIR" >> $GITHUB_ENV
          echo "✓ Test directory created at $TEST_DIR"

      - name: Initialize project with CLI
        working-directory: cli
        shell: bash
        run: |
          if ! ./${{ matrix.binary }} init --cwd "$TEST_DIR" --debug; then
            echo "❌ Project initialization failed, checking server health..."
            curl -s http://localhost:14345/health | jq '.' || echo "Server not reachable"
            exit 1
          fi
          echo "✓ Project initialized"

      - name: Verify project config was created
        shell: bash
        run: |
          if [ ! -f "$TEST_DIR/llamafarm.yaml" ]; then
            echo "❌ Error: llamafarm.yaml not created"
            exit 1
          fi
          echo "✓ Project configuration exists"
          echo ""
          echo "=== FULL CONFIG AFTER INIT ==="
          cat "$TEST_DIR/llamafarm.yaml"
          echo ""
          echo "=== Checking critical fields ==="
          echo "namespace: $(grep '^namespace:' "$TEST_DIR/llamafarm.yaml" || echo 'MISSING')"
          echo "name: $(grep '^name:' "$TEST_DIR/llamafarm.yaml" || echo 'MISSING')"
          echo "prompts.name: $(grep -A2 '^prompts:' "$TEST_DIR/llamafarm.yaml" | grep 'name:' | head -1 || echo 'MISSING')"

      - name: Switch to tiny models for fast CI testing
        shell: bash
        run: |
          echo "Switching to tiny models for faster CI execution..."
          # Install yq if not available
          if ! command -v yq &> /dev/null; then
            echo "Installing yq..."
            if [ "$RUNNER_OS" = "macOS" ]; then
              brew install yq
            elif [ "$RUNNER_OS" = "Windows" ]; then
              choco install yq -y
            else
              sudo wget -qO /usr/local/bin/yq https://github.com/mikefarah/yq/releases/latest/download/yq_linux_amd64
              sudo chmod +x /usr/local/bin/yq
            fi
          fi

          # Update runtime model and quantization
          yq -i '.runtime.models[0].model = "unsloth/Qwen3-0.6B-GGUF:IQ1_S"' "$TEST_DIR/llamafarm.yaml"

          # Update embedding model and dimension
          yq -i '.rag.databases[0].embedding_strategies[0].config.model = "sentence-transformers/all-MiniLM-L6-v2"' "$TEST_DIR/llamafarm.yaml"
          yq -i '.rag.databases[0].embedding_strategies[0].config.dimension = 384' "$TEST_DIR/llamafarm.yaml"

          echo "✓ Model configuration updated"
          echo ""
          echo "=== Updated runtime config ==="
          yq '.runtime.models[0]' "$TEST_DIR/llamafarm.yaml"
          echo ""
          echo "=== Updated embedding config ==="
          yq '.rag.databases[0].embedding_strategies[0].config | pick(["model", "dimension"])' "$TEST_DIR/llamafarm.yaml"

          # Verify the changes took effect
          RUNTIME_MODEL=$(yq '.runtime.models[0].model' "$TEST_DIR/llamafarm.yaml")
          if [ "$RUNTIME_MODEL" != "unsloth/Qwen3-0.6B-GGUF:IQ1_S" ]; then
            echo "❌ Model configuration update failed!"
            echo "Expected: unsloth/Qwen3-0.6B-GGUF:IQ1_S"
            echo "Got: $RUNTIME_MODEL"
            exit 1
          fi
          echo "✓ Model configuration verified"

      - name: Pre-warm models by loading them
        working-directory: cli
        shell: bash
        timeout-minutes: 8
        env:
          PYTHONUNBUFFERED: "1"
          HF_HUB_ENABLE_HF_TRANSFER: "1" # Use faster download method
        run: |
          echo "Pre-warming models (downloading and loading)..."
          echo "Model: unsloth/Qwen3-0.6B-GGUF (IQ1_S quantization)"
          echo "Expected size: ~50-100MB"
          echo ""

          # Use a simple query to trigger model loading
          # The --no-rag flag means we only need to load the language model, not embeddings yet
          START_TIME=$(date +%s)
          if ./${{ matrix.binary }} --cwd "$TEST_DIR" --debug chat --no-rag "hi" 2>&1 | tee /tmp/prewarm.log; then
            END_TIME=$(date +%s)
            DURATION=$((END_TIME - START_TIME))
            echo ""

            # Check that the response isn't a fallback/error response
            # These patterns indicate the model failed to load but we got an error echo back
            RESPONSE=$(cat /tmp/prewarm.log)
            if echo "$RESPONSE" | grep -qi "I notice my previous response"; then
              echo "❌ Model pre-warming failed - got fallback error response!"
              echo "Response indicates model loading failed."
              echo ""
              echo "Full response:"
              echo "$RESPONSE"
              exit 1
            fi

            if echo "$RESPONSE" | grep -qi "error loading model\|failed to load model\|no backends are loaded"; then
              echo "❌ Model pre-warming failed - error detected in response!"
              echo ""
              echo "Full response:"
              echo "$RESPONSE"
              exit 1
            fi

            echo "✓ Models successfully pre-warmed in ${DURATION}s"
          else
            echo ""
            echo "❌ Model pre-warming failed!"
            echo "Checking server health..."
            curl -s http://localhost:14345/health | jq '.' || echo "Server not reachable"
            echo ""
            echo "Last 50 lines of output:"
            tail -50 /tmp/prewarm.log
            exit 1
          fi

      # ============================================================
      # Verify llama.cpp Binary Download (critical for GGUF models)
      # ============================================================
      - name: Verify llama.cpp binary download
        shell: bash
        run: |
          echo "Verifying llama.cpp binary installation..."

          # Determine cache directory based on OS
          if [ "$RUNNER_OS" = "macOS" ]; then
            LLAMA_CACHE="$HOME/Library/Caches/llamafarm-llama"
            LIB_NAME="libllama.dylib"
          elif [ "$RUNNER_OS" = "Windows" ]; then
            # Convert Windows path to Unix-style for bash compatibility
            LLAMA_CACHE="$(cygpath -u "$LOCALAPPDATA")/llamafarm-llama/cache"
            LIB_NAME="llama.dll"
          else
            LLAMA_CACHE="$HOME/.cache/llamafarm-llama"
            LIB_NAME="libllama.so"
          fi

          # Strip both LF and CR to handle Windows CRLF line endings
          LLAMA_VERSION=$(cat llama-cpp-version.txt | tr -d '\r\n')
          LIB_PATH="$LLAMA_CACHE/$LLAMA_VERSION/$LIB_NAME"

          echo "Expected binary location: $LIB_PATH"
          echo ""
          echo "Cache directory contents:"
          ls -la "$LLAMA_CACHE/$LLAMA_VERSION/" 2>/dev/null || echo "Cache directory does not exist"
          echo ""

          # Check if binary exists (could be a file or symlink)
          if [ ! -e "$LIB_PATH" ]; then
            echo "❌ llama.cpp binary not found at $LIB_PATH"
            exit 1
          fi

          # Check if it's a symlink and follow it
          ACTUAL_PATH="$LIB_PATH"
          if [ -L "$LIB_PATH" ]; then
            echo "Found symlink: $LIB_NAME -> $(readlink "$LIB_PATH")"
            # Follow symlink chain to find actual file
            ACTUAL_PATH=$(readlink -f "$LIB_PATH" 2>/dev/null || python3 -c "import os; print(os.path.realpath('$LIB_PATH'))")
            echo "Resolved to: $ACTUAL_PATH"
          fi

          # Verify the actual file exists and has reasonable size
          if [ ! -f "$ACTUAL_PATH" ]; then
            echo "❌ Resolved path $ACTUAL_PATH is not a file"
            exit 1
          fi

          # Check file size (should be > 1MB for a real library)
          # Use -L flag with stat to follow symlinks
          FILE_SIZE=$(stat -f%z "$ACTUAL_PATH" 2>/dev/null || stat -c%s "$ACTUAL_PATH" 2>/dev/null)
          echo "Binary size: $FILE_SIZE bytes"

          if [ "$FILE_SIZE" -lt 1000000 ]; then
            echo "❌ Binary file is too small ($FILE_SIZE bytes), may be corrupted"
            echo "File contents (if text):"
            head -c 200 "$ACTUAL_PATH" 2>/dev/null || true
            exit 1
          fi

          # On macOS, verify it's a valid Mach-O binary and check dependencies
          if [ "$RUNNER_OS" = "macOS" ]; then
            FILE_TYPE=$(file "$ACTUAL_PATH")
            echo "File type: $FILE_TYPE"
            if echo "$FILE_TYPE" | grep -q "Mach-O"; then
              echo "✓ Valid Mach-O binary"
            else
              echo "⚠ Warning: Not recognized as Mach-O binary"
            fi

            echo ""
            echo "Checking macOS dependencies..."
            CACHE_DIR="$LLAMA_CACHE/$LLAMA_VERSION"
            DYLIB_COUNT=$(find "$CACHE_DIR" -maxdepth 1 -name "*.dylib" 2>/dev/null | wc -l || echo "0")
            echo "Found $DYLIB_COUNT .dylib files in cache:"
            ls -la "$CACHE_DIR"/*.dylib 2>/dev/null || echo "Could not list .dylib files"

            # Check for common dependencies
            for dep in libggml.dylib libggml.0.dylib libggml-base.dylib libggml-cpu.dylib; do
              if [ -e "$CACHE_DIR/$dep" ]; then
                echo "  ✓ $dep found"
              else
                echo "  ⚠ $dep not found"
              fi
            done
          fi

          # On Linux, verify it's a valid ELF binary and check dependencies
          if [ "$RUNNER_OS" = "Linux" ]; then
            FILE_TYPE=$(file "$ACTUAL_PATH")
            echo "File type: $FILE_TYPE"
            if echo "$FILE_TYPE" | grep -q "ELF"; then
              echo "✓ Valid ELF binary"
            else
              echo "⚠ Warning: Not recognized as ELF binary"
            fi

            echo ""
            echo "Checking Linux dependencies..."
            CACHE_DIR="$LLAMA_CACHE/$LLAMA_VERSION"
            SO_COUNT=$(find "$CACHE_DIR" -maxdepth 1 -name "*.so*" 2>/dev/null | wc -l || echo "0")
            echo "Found $SO_COUNT .so files in cache:"
            ls -la "$CACHE_DIR"/*.so* 2>/dev/null || echo "Could not list .so files"

            # Check for common dependencies
            for dep in libggml.so libggml.so.0 libggml-base.so libggml-cpu.so; do
              if [ -e "$CACHE_DIR/$dep" ]; then
                echo "  ✓ $dep found"
              else
                echo "  ⚠ $dep not found"
              fi
            done
          fi

          # On Windows, verify dependencies are present
          if [ "$RUNNER_OS" = "Windows" ]; then
            echo ""
            echo "Checking Windows dependencies..."
            CACHE_DIR="$LLAMA_CACHE/$LLAMA_VERSION"
            DLL_COUNT=$(find "$CACHE_DIR" -maxdepth 1 -name "*.dll" 2>/dev/null | wc -l || ls "$CACHE_DIR"/*.dll 2>/dev/null | wc -l || echo "0")
            echo "Found $DLL_COUNT DLL files in cache:"
            ls -la "$CACHE_DIR"/*.dll 2>/dev/null || dir "$CACHE_DIR\\*.dll" 2>/dev/null || echo "Could not list DLLs"

            # Check for common dependencies
            for dep in ggml.dll ggml-base.dll ggml-cpu.dll; do
              if [ -f "$CACHE_DIR/$dep" ]; then
                echo "  ✓ $dep found"
              fi
            done
          fi

          echo ""
          echo "✓ llama.cpp binary verified successfully"
          echo "  Version: $LLAMA_VERSION"
          echo "  Path: $LIB_PATH"
          if [ "$ACTUAL_PATH" != "$LIB_PATH" ]; then
            echo "  Actual: $ACTUAL_PATH"
          fi
          echo "  Size: $FILE_SIZE bytes"

      # ============================================================
      # Data Ingestion Test
      # ============================================================
      - name: Create dataset
        working-directory: cli
        shell: bash
        env:
          PYTHONUNBUFFERED: "1"
        run: |
          if ! ./${{ matrix.binary }} --cwd "$TEST_DIR" --debug datasets create \
            -s universal_rag \
            -b main_database \
            test_dataset; then
            echo "❌ Dataset creation failed, checking server health..."
            curl -s http://localhost:14345/health | jq '.' || echo "Server not reachable"
            exit 1
          fi
          echo "✓ Dataset created"

      - name: Wait for config sync after dataset create
        shell: bash
        run: sleep 2.5

      - name: Debug config after dataset create
        shell: bash
        run: |
          echo ""
          echo "=== Config after dataset create (first 40 lines) ==="
          head -40 "$TEST_DIR/llamafarm.yaml"
          echo ""
          echo "=== Checking critical fields ==="
          echo "namespace: $(grep '^namespace:' "$TEST_DIR/llamafarm.yaml" || echo 'MISSING')"
          echo "name: $(grep '^name:' "$TEST_DIR/llamafarm.yaml" || echo 'MISSING')"
          echo "prompts.name: $(grep -A2 '^prompts:' "$TEST_DIR/llamafarm.yaml" | grep 'name:' | head -1 || echo 'MISSING')"
          echo "datasets: $(grep -A5 '^datasets:' "$TEST_DIR/llamafarm.yaml" | head -6)"

      - name: Upload sample files
        working-directory: cli
        shell: bash
        env:
          PYTHONUNBUFFERED: "1"
        run: |
          if ! ./${{ matrix.binary }} --cwd "$TEST_DIR" --debug datasets upload test_dataset "../examples/quick_rag/files"; then
            echo "❌ Upload failed for ../examples/quick_rag/files, checking server health..."
            echo "Current directory: $(pwd)"
            curl -s http://localhost:14345/health | jq '.' || echo "Server not reachable"
            exit 1
          fi
          echo "✓ All sample files uploaded"

      - name: Wait for config sync after dataset upload
        shell: bash
        run: sleep 2.5

      - name: Debug config before dataset process
        shell: bash
        run: |
          echo ""
          echo "=== Config before dataset process ==="
          echo "File exists: $(test -f "$TEST_DIR/llamafarm.yaml" && echo 'YES' || echo 'NO')"
          if [ -f "$TEST_DIR/llamafarm.yaml" ]; then
            echo "File size: $(wc -c < "$TEST_DIR/llamafarm.yaml")"
          else
            echo "File size: N/A"
          fi
          echo ""
          echo "=== Full config content ==="
          cat "$TEST_DIR/llamafarm.yaml" || echo "Failed to read config"
          echo ""
          echo "=== Critical fields check ==="
          echo "namespace: $(grep '^namespace:' "$TEST_DIR/llamafarm.yaml" || echo 'MISSING')"
          echo "name: $(grep '^name:' "$TEST_DIR/llamafarm.yaml" || echo 'MISSING')"
          echo "prompts.name: $(grep -A2 '^prompts:' "$TEST_DIR/llamafarm.yaml" | grep 'name:' | head -1 || echo 'MISSING')"

      - name: Process dataset
        working-directory: cli
        shell: bash
        env:
          PYTHONUNBUFFERED: "1"
        run: |
          sleep 2
          if ! ./${{ matrix.binary }} --cwd "$TEST_DIR" --debug datasets process test_dataset; then
            echo "❌ Dataset processing failed, checking server health..."
            curl -s http://localhost:14345/health | jq '.' || echo "Server not reachable"
            exit 1
          fi
          echo "✓ Dataset processing complete"

      # ============================================================
      # RAG Query Test
      # ============================================================
      - name: Run RAG query
        working-directory: cli
        shell: bash
        env:
          PYTHONUNBUFFERED: "1"
        run: |
          echo "Running RAG query..."
          if ! OUTPUT=$(./${{ matrix.binary }} --cwd "$TEST_DIR" --debug rag query \
            --database main_database \
            --top-k 3 \
            "neural scaling laws" 2>&1); then
            echo "❌ RAG query command failed"
            echo "$OUTPUT"
            echo "Checking server health..."
            curl -s http://localhost:14345/health | jq '.' || echo "Server not reachable"
            exit 1
          fi

          echo "$OUTPUT"

          # Verify output is not empty
          if [ -z "$OUTPUT" ]; then
            echo "❌ Error: RAG query returned empty output"
            curl -s http://localhost:14345/health | jq '.' || echo "Server not reachable"
            exit 1
          fi

          echo "✓ RAG query returned results"

      - name: Validate RAG query results
        working-directory: cli
        shell: bash
        env:
          PYTHONUNBUFFERED: "1"
        run: |
          if ! OUTPUT=$(./${{ matrix.binary }} --cwd "$TEST_DIR" --debug rag query \
            --database main_database \
            --top-k 3 \
            --include-metadata \
            "neural scaling laws" 2>&1); then
            echo "❌ RAG query validation failed"
            echo "$OUTPUT"
            echo "Checking server health..."
            curl -s http://localhost:14345/health | jq '.' || echo "Server not reachable"
            exit 1
          fi

          # Check if output contains expected content
          if echo "$OUTPUT" | grep -q "neural"; then
            echo "✓ RAG query results contain relevant content"
          else
            echo "⚠ Warning: Results may not contain expected content"
            echo "$OUTPUT"
          fi

      # ============================================================
      # Chat Command Test
      # ============================================================
      - name: Run chat command with RAG
        working-directory: cli
        shell: bash
        env:
          PYTHONUNBUFFERED: "1"
        run: |
          echo "Running chat command with RAG..."
          if ! OUTPUT=$(./${{ matrix.binary }} --cwd "$TEST_DIR" --debug chat \
            "Summarize neural scaling laws in one sentence" 2>&1); then
            echo "❌ Chat command failed"
            echo "$OUTPUT"
            echo "Checking server health..."
            curl -s http://localhost:14345/health | jq '.' || echo "Server not reachable"
            exit 1
          fi

          echo "Chat response:"
          echo "$OUTPUT"

          # Verify output is not empty
          if [ -z "$OUTPUT" ]; then
            echo "❌ Error: Chat command returned empty output"
            curl -s http://localhost:14345/health | jq '.' || echo "Server not reachable"
            exit 1
          fi

          # Check if output contains some text (at least 10 characters)
          if [ ${#OUTPUT} -lt 10 ]; then
            echo "❌ Error: Chat response too short, possible error"
            curl -s http://localhost:14345/health | jq '.' || echo "Server not reachable"
            exit 1
          fi

          echo "✓ Chat command returned a response"

      - name: Test chat command without RAG
        working-directory: cli
        shell: bash
        env:
          PYTHONUNBUFFERED: "1"
        run: |
          echo "Running chat command without RAG..."
          if ! OUTPUT=$(./${{ matrix.binary }} --cwd "$TEST_DIR" --debug chat \
            --no-rag \
            "What is 2 + 2?" 2>&1); then
            echo "❌ Chat command (no RAG) failed"
            echo "$OUTPUT"
            echo "Checking server health..."
            curl -s http://localhost:14345/health | jq '.' || echo "Server not reachable"
            exit 1
          fi

          echo "Chat response:"
          echo "$OUTPUT"

          # Verify output is not empty
          if [ -z "$OUTPUT" ]; then
            echo "❌ Error: Chat command (no RAG) returned empty output"
            curl -s http://localhost:14345/health | jq '.' || echo "Server not reachable"
            exit 1
          fi

          echo "✓ Chat command without RAG works"

      # ============================================================
      # Validation & Summary
      # ============================================================
      - name: List datasets to verify persistence
        working-directory: cli
        shell: bash
        env:
          PYTHONUNBUFFERED: "1"
        run: |
          echo "Listing datasets..."
          if ! ./${{ matrix.binary }} --cwd "$TEST_DIR" --debug datasets list; then
            echo "❌ Dataset listing failed, checking server health..."
            curl -s http://localhost:14345/health | jq '.' || echo "Server not reachable"
            exit 1
          fi
          echo "✓ Dataset listing works"

      - name: Check RAG health
        working-directory: cli
        shell: bash
        env:
          PYTHONUNBUFFERED: "1"
        run: |
          echo "Checking RAG health..."
          ./${{ matrix.binary }} --cwd "$TEST_DIR" --debug rag health || true
          echo "✓ RAG health check complete"

      - name: E2E test summary
        shell: bash
        run: |
          echo "=========================================="
          echo "End-to-End Test Summary (${{ matrix.os }})"
          echo "=========================================="
          echo "✓ CLI binary downloaded and verified"
          echo "✓ Project initialized"
          echo "✓ llama.cpp binary downloaded and verified"
          echo "✓ GGUF model loaded successfully"
          echo "✓ Dataset created and processed"
          echo "✓ RAG queries executed"
          echo "✓ Chat commands completed"
          echo "=========================================="
          echo "All E2E tests passed!"

      # ============================================================
      # Save Results for Aggregation
      # ============================================================
      - name: Save test result for aggregation
        if: always()
        shell: bash
        run: |
          mkdir -p e2e-results
          echo "${{ job.status }}" > e2e-results/${{ matrix.os }}.txt
          echo "Saved result: ${{ job.status }} for ${{ matrix.os }}"

      - name: Upload test result artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: e2e-result-${{ matrix.os }}
          path: e2e-results/
          retention-days: 1

      # ============================================================
      # Cleanup
      # ============================================================
      - name: Cleanup test artifacts
        if: always()
        shell: bash
        run: |
          echo "Cleaning up test directory..."
          rm -rf "$TEST_DIR"
          echo "✓ Cleanup complete"

      - name: Display service logs on failure
        if: failure()
        shell: bash
        run: |
          echo "=========================================="
          echo "Service Logs (${{ matrix.os }})"
          echo "=========================================="

          # Determine home directory (cross-platform)
          if [ "$RUNNER_OS" = "Windows" ]; then
            LF_HOME="$USERPROFILE/.llamafarm"
          else
            LF_HOME="$HOME/.llamafarm"
          fi

          # Display server logs if they exist
          if [ -f "$LF_HOME/logs/server.log" ]; then
            echo "--- Server Logs ---"
            tail -100 "$LF_HOME/logs/server.log"
          else
            echo "No server logs found at $LF_HOME/logs/server.log"
          fi

          echo ""

          # Display RAG logs if they exist
          if [ -f "$LF_HOME/logs/rag.log" ]; then
            echo "--- RAG Worker Logs ---"
            tail -100 "$LF_HOME/logs/rag.log"
          else
            echo "No RAG logs found at $LF_HOME/logs/rag.log"
          fi

          echo ""

          # Display Universal Runtime logs if they exist
          if [ -f "$LF_HOME/logs/universal-runtime.log" ]; then
            echo "--- Universal Runtime Logs ---"
            tail -100 "$LF_HOME/logs/universal-runtime.log"
          else
            echo "No Universal Runtime logs found at $LF_HOME/logs/universal-runtime.log"
          fi

          echo ""

          # Display llama.cpp cache directory status (for debugging binary download issues)
          echo "--- llama.cpp Binary Cache Status ---"
          if [ "$RUNNER_OS" = "macOS" ]; then
            LLAMA_CACHE="$HOME/Library/Caches/llamafarm-llama"
          elif [ "$RUNNER_OS" = "Windows" ]; then
            # Convert Windows path to Unix-style for bash compatibility
            LLAMA_CACHE="$(cygpath -u "$LOCALAPPDATA")/llamafarm-llama/cache"
          else
            LLAMA_CACHE="$HOME/.cache/llamafarm-llama"
          fi

          echo "Cache directory: $LLAMA_CACHE"
          if [ -d "$LLAMA_CACHE" ]; then
            echo "Contents:"
            ls -laR "$LLAMA_CACHE" 2>/dev/null || dir /s "$LLAMA_CACHE" 2>/dev/null || echo "Could not list cache contents"
          else
            echo "Cache directory does not exist - binary may not have been downloaded"
          fi

      - name: Upload logs on failure
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: e2e-test-logs-${{ matrix.os }}
          path: |
            ~/.llamafarm/logs/
            ~/Library/Caches/llamafarm-llama/
            ~/.cache/llamafarm-llama/
          retention-days: 7
          if-no-files-found: warn

  # ============================================================
  # Aggregated PR Comment Job
  # Note: This job is skipped for fork PRs due to GitHub's security model
  # which limits GITHUB_TOKEN to read-only for workflows triggered by forks.
  # ============================================================
  report-results:
    name: Report E2E Results
    needs: e2e-test
    # Only run for non-fork PRs (fork PRs have head.repo.fork = true)
    if: always() && github.event_name == 'pull_request' && github.event.pull_request.head.repo.fork == false
    runs-on: ubuntu-latest
    steps:
      - name: Download all result artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: e2e-result-*
          path: results/
          merge-multiple: false

      - name: Get PR info
        id: pr-info
        run: |
          echo "pr_number=${{ github.event.pull_request.number }}" >> $GITHUB_OUTPUT
          echo "head_sha=${{ github.event.pull_request.head.sha }}" >> $GITHUB_OUTPUT

      - name: Build aggregated results summary
        id: build-summary
        env:
          HEAD_SHA: ${{ steps.pr-info.outputs.head_sha }}
        run: |
          WORKFLOW_RUN_URL="${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"

          # Initialize counters
          TOTAL=0
          PASSED=0
          FAILED=0
          CANCELLED=0

          # Build results table
          RESULTS_TABLE="| OS | Status |\n|---|---|\n"

          for os in ubuntu-latest macos-latest windows-latest; do
            RESULT_FILE="results/e2e-result-${os}/${os}.txt"
            if [ -f "$RESULT_FILE" ]; then
              STATUS=$(cat "$RESULT_FILE")
              TOTAL=$((TOTAL + 1))
              case "$STATUS" in
                success)
                  PASSED=$((PASSED + 1))
                  RESULTS_TABLE="${RESULTS_TABLE}| ${os} | :white_check_mark: Passed |\n"
                  ;;
                failure)
                  FAILED=$((FAILED + 1))
                  RESULTS_TABLE="${RESULTS_TABLE}| ${os} | :x: Failed |\n"
                  ;;
                cancelled)
                  CANCELLED=$((CANCELLED + 1))
                  RESULTS_TABLE="${RESULTS_TABLE}| ${os} | :warning: Cancelled |\n"
                  ;;
                *)
                  RESULTS_TABLE="${RESULTS_TABLE}| ${os} | :question: ${STATUS} |\n"
                  ;;
              esac
            else
              echo "Warning: No result file found for ${os}"
              RESULTS_TABLE="${RESULTS_TABLE}| ${os} | :grey_question: No result |\n"
            fi
          done

          # Determine overall status
          if [ "$FAILED" -gt 0 ]; then
            STATUS_EMOJI=":x:"
            STATUS_TEXT="**E2E Tests Failed**"
          elif [ "$CANCELLED" -gt 0 ]; then
            STATUS_EMOJI=":warning:"
            STATUS_TEXT="**E2E Tests Cancelled**"
          elif [ "$PASSED" -eq "$TOTAL" ] && [ "$TOTAL" -gt 0 ]; then
            STATUS_EMOJI=":white_check_mark:"
            STATUS_TEXT="**All E2E Tests Passed!**"
          else
            STATUS_EMOJI=":grey_question:"
            STATUS_TEXT="**E2E Tests completed with unknown status**"
          fi

          # Build the comment body and save to file
          {
            echo "## ${STATUS_EMOJI} ${STATUS_TEXT}"
            echo ""
            echo "### Test Results by Platform"
            echo ""
            echo -e "$RESULTS_TABLE"
            echo ""
            echo "### Summary"
            echo ""
            echo "- **Passed**: ${PASSED}/${TOTAL}"
            if [ "$FAILED" -gt 0 ]; then
              echo "- **Failed**: ${FAILED}"
            fi
            if [ "$CANCELLED" -gt 0 ]; then
              echo "- **Cancelled**: ${CANCELLED}"
            fi
            echo "- **Workflow Run**: [View Details](${WORKFLOW_RUN_URL})"
            echo "- **Commit**: \`${HEAD_SHA:0:7}\`"
            echo ""
            echo "---"
            echo "*This comment was automatically generated by the E2E Tests workflow.*"
          } > comment-body.txt

          echo "Comment body prepared:"
          cat comment-body.txt

      - name: Find existing comment
        id: find-comment
        uses: actions/github-script@v7
        env:
          PR_NUMBER: ${{ steps.pr-info.outputs.pr_number }}
        with:
          script: |
            const prNumber = process.env.PR_NUMBER;
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: prNumber,
            });

            // Find comment from this bot (contains the marker)
            const botComment = comments.find(comment =>
              comment.user.type === 'Bot' &&
              comment.body.includes('*This comment was automatically generated by the E2E Tests workflow.*')
            );

            if (botComment) {
              core.setOutput('comment_id', botComment.id);
              core.setOutput('exists', 'true');
              console.log(`Found existing comment: ${botComment.id}`);
            } else {
              core.setOutput('exists', 'false');
              console.log('No existing comment found');
            }

      - name: Post or update PR comment
        uses: actions/github-script@v7
        env:
          PR_NUMBER: ${{ steps.pr-info.outputs.pr_number }}
        with:
          retries: 3
          script: |
            const fs = require('fs');
            const prNumber = process.env.PR_NUMBER;

            if (!fs.existsSync('comment-body.txt')) {
              console.log('Comment file not found');
              return;
            }

            const commentBody = fs.readFileSync('comment-body.txt', 'utf8');
            const commentExists = '${{ steps.find-comment.outputs.exists }}' === 'true';
            const existingCommentId = '${{ steps.find-comment.outputs.comment_id }}';

            if (commentExists && existingCommentId) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: existingCommentId,
                body: commentBody
              });
              console.log(`Updated existing comment #${existingCommentId} on PR #${prNumber}`);
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: prNumber,
                body: commentBody
              });
              console.log(`Created new comment on PR #${prNumber}`);
            }
