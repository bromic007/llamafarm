/**
 * AUTO-GENERATED - DO NOT EDIT
 * Generated from rag/schema.yaml by designer/generate-types.ts
 */

// ============================================================================
// Parser Config Interfaces (generated by json-schema-to-typescript)
// ============================================================================

export interface AutoParserConfiguration {
  /**
   * Chunk size for text splitting
   */
  chunk_size?: number;
  /**
   * Overlap between chunks
   */
  chunk_overlap?: number;
}

/**
 * Enhanced PDF parser using PyPDF2 with comprehensive capabilities
 */
export interface PDFParserPyPDF2Configuration {
  /**
   * Chunk size in characters
   */
  chunk_size?: number;
  /**
   * Overlap between chunks in characters
   */
  chunk_overlap?: number;
  /**
   * Chunking strategy using PyPDF2 text structure
   */
  chunk_strategy?: 'paragraphs' | 'sentences' | 'characters';
  /**
   * Extract PDF metadata using PyPDF2
   */
  extract_metadata?: boolean;
  /**
   * Use PyPDF2 layout-preserving extraction mode
   */
  preserve_layout?: boolean;
  /**
   * Extract page numbers and rotation info
   */
  extract_page_info?: boolean;
  /**
   * Extract PDF annotations using PyPDF2
   */
  extract_annotations?: boolean;
  /**
   * Extract hyperlinks
   */
  extract_links?: boolean;
  /**
   * Extract form fields using PyPDF2
   */
  extract_form_fields?: boolean;
  /**
   * Extract document outlines/bookmarks
   */
  extract_outlines?: boolean;
  /**
   * Extract embedded images using PyPDF2
   */
  extract_images?: boolean;
  /**
   * Extract XMP metadata using PyPDF2
   */
  extract_xmp_metadata?: boolean;
  /**
   * Clean extracted text
   */
  clean_text?: boolean;
  /**
   * Combine all pages into a single document. MUST be false to enable chunking.
   */
  combine_pages?: boolean;
}

/**
 * Advanced CSV parser using Pandas with data analysis capabilities
 */
export interface CSVParserPandasConfiguration {
  /**
   * Number of rows per chunk
   */
  chunk_size?: number;
  /**
   * How to chunk the CSV data
   */
  chunk_strategy?: 'rows' | 'columns' | 'full';
  /**
   * Extract data statistics and metadata
   */
  extract_metadata?: boolean;
  /**
   * File encoding
   */
  encoding?: string;
  /**
   * CSV delimiter
   */
  delimiter?: string;
  /**
   * Values to treat as NaN
   */
  na_values?: string[];
}

/**
 * Simple CSV parser using native Python csv module
 */
export interface CSVParserPythonConfiguration {
  /**
   * Number of rows per chunk
   */
  chunk_size?: number;
  /**
   * File encoding
   */
  encoding?: string;
  /**
   * CSV delimiter
   */
  delimiter?: string;
  /**
   * Quote character
   */
  quotechar?: string;
}

/**
 * Excel parser using OpenPyXL for XLSX files with formula support
 */
export interface ExcelParserOpenPyXLConfiguration {
  /**
   * Number of rows per chunk
   */
  chunk_size?: number;
  /**
   * Extract cell formulas using OpenPyXL
   */
  extract_formulas?: boolean;
  /**
   * Extract workbook metadata
   */
  extract_metadata?: boolean;
  /**
   * Specific sheets to process (null = all)
   */
  sheets?: string[] | null;
  /**
   * Extract values instead of formulas
   */
  data_only?: boolean;
}

/**
 * Excel parser using Pandas with data analysis capabilities
 */
export interface ExcelParserPandasConfiguration {
  /**
   * Number of rows per chunk
   */
  chunk_size?: number;
  /**
   * Specific sheets to process (null = all)
   */
  sheets?: string[] | null;
  /**
   * Extract data statistics
   */
  extract_metadata?: boolean;
  /**
   * Rows to skip at beginning
   */
  skiprows?: number | null;
  /**
   * Values to treat as NaN
   */
  na_values?: string[];
}

/**
 * Word document parser using python-docx library
 */
export interface DOCXParserPythonDocxConfiguration {
  /**
   * Chunk size in characters
   */
  chunk_size?: number;
  /**
   * Chunking strategy
   */
  chunk_strategy?: 'paragraphs' | 'sentences' | 'characters';
  /**
   * Extract document metadata
   */
  extract_metadata?: boolean;
  /**
   * Extract tables using python-docx
   */
  extract_tables?: boolean;
  /**
   * Extract headers
   */
  extract_headers?: boolean;
  /**
   * Extract footers
   */
  extract_footers?: boolean;
  /**
   * Extract comments
   */
  extract_comments?: boolean;
}

/**
 * Markdown parser using native Python with regex parsing
 */
export interface MarkdownParserPythonConfiguration {
  /**
   * Chunk size in characters
   */
  chunk_size?: number;
  /**
   * Chunking strategy - sections uses markdown headers
   */
  chunk_strategy?: 'sections' | 'paragraphs' | 'characters';
  /**
   * Extract YAML frontmatter
   */
  extract_metadata?: boolean;
  /**
   * Extract code blocks
   */
  extract_code_blocks?: boolean;
  /**
   * Extract markdown links
   */
  extract_links?: boolean;
}

/**
 * Text parser using native Python with encoding detection
 */
export interface TextParserPythonConfiguration {
  /**
   * Chunk size in characters
   */
  chunk_size?: number;
  /**
   * Overlap between chunks
   */
  chunk_overlap?: number;
  /**
   * Text chunking strategy
   */
  chunk_strategy?: 'sentences' | 'paragraphs' | 'characters';
  /**
   * Text encoding (utf-8 or auto-detect)
   */
  encoding?: string;
  /**
   * Remove excessive whitespace
   */
  clean_text?: boolean;
  /**
   * Extract file statistics
   */
  extract_metadata?: boolean;
}

/**
 * Advanced text parser using LlamaIndex with semantic splitting, code parsing, and multi-format support
 */
export interface TextParserLlamaIndexConfiguration {
  /**
   * Chunk size in characters
   */
  chunk_size?: number;
  /**
   * Overlap between chunks
   */
  chunk_overlap?: number;
  /**
   * Advanced chunking strategy - semantic uses content-based splitting, code preserves syntax
   */
  chunk_strategy?: 'characters' | 'sentences' | 'paragraphs' | 'tokens' | 'semantic' | 'code';
  /**
   * Text encoding
   */
  encoding?: string;
  /**
   * Clean extracted text
   */
  clean_text?: boolean;
  /**
   * Extract comprehensive file and content metadata
   */
  extract_metadata?: boolean;
  /**
   * Buffer size for semantic chunking
   */
  semantic_buffer_size?: number;
  /**
   * Percentile threshold for semantic breakpoints
   */
  semantic_breakpoint_percentile_threshold?: number;
  /**
   * Tokenizer model for token-based chunking
   */
  token_model?: string;
  /**
   * Preserve code syntax and structure when parsing code files
   */
  preserve_code_structure?: boolean;
  /**
   * Automatically detect programming language for code files
   */
  detect_language?: boolean;
  /**
   * Include relationships between chunks for better context
   */
  include_prev_next_rel?: boolean;
}

/**
 * Advanced PDF parser using LlamaIndex with multiple fallback strategies
 */
export interface PDFParserLlamaIndexConfiguration {
  /**
   * Chunk size in characters
   */
  chunk_size?: number;
  /**
   * Overlap between chunks
   */
  chunk_overlap?: number;
  /**
   * Chunking strategy for PDF content
   */
  chunk_strategy?: 'sentences' | 'paragraphs' | 'pages' | 'semantic';
  /**
   * Extract PDF metadata
   */
  extract_metadata?: boolean;
  /**
   * Extract images from PDF
   */
  extract_images?: boolean;
  /**
   * Extract tables from PDF
   */
  extract_tables?: boolean;
  /**
   * Fallback strategies to try in order
   */
  fallback_strategies?: ('llama_pdf_reader' | 'llama_pymupdf_reader' | 'direct_pymupdf' | 'pypdf2_fallback')[];
}

/**
 * CSV parser using LlamaIndex with Pandas backend for advanced processing
 */
export interface CSVParserLlamaIndexConfiguration {
  /**
   * Number of rows per chunk
   */
  chunk_size?: number;
  /**
   * Chunking strategy
   */
  chunk_strategy?: 'rows' | 'semantic' | 'full';
  /**
   * Map CSV columns to standard fields
   */
  field_mapping?: {
    [k: string]: string;
  };
  /**
   * Extract metadata from CSV
   */
  extract_metadata?: boolean;
  /**
   * Combine fields into text content
   */
  combine_fields?: boolean;
  /**
   * Number of rows to skip at beginning
   */
  skiprows?: number;
  /**
   * Values to treat as missing
   */
  na_values?: string[];
}

/**
 * Excel parser using LlamaIndex with Pandas backend for advanced processing
 */
export interface ExcelParserLlamaIndexConfiguration {
  /**
   * Number of rows per chunk
   */
  chunk_size?: number;
  /**
   * Chunking strategy
   */
  chunk_strategy?: 'rows' | 'semantic' | 'full';
  /**
   * Specific sheets to parse (null for all)
   */
  sheets?: string[] | null;
  /**
   * Combine all sheets into one document
   */
  combine_sheets?: boolean;
  /**
   * Extract metadata from Excel
   */
  extract_metadata?: boolean;
  /**
   * Extract formulas instead of values
   */
  extract_formulas?: boolean;
  /**
   * Row index for headers
   */
  header_row?: number;
  /**
   * Number of rows to skip
   */
  skiprows?: number;
  /**
   * Values to treat as missing
   */
  na_values?: string[];
}

/**
 * Advanced DOCX parser using LlamaIndex with enhanced chunking
 */
export interface DOCXParserLlamaIndexConfiguration {
  /**
   * Chunk size in characters
   */
  chunk_size?: number;
  /**
   * Overlap between chunks
   */
  chunk_overlap?: number;
  /**
   * Chunking strategy
   */
  chunk_strategy?: 'paragraphs' | 'sentences' | 'semantic';
  /**
   * Extract document metadata
   */
  extract_metadata?: boolean;
  /**
   * Extract tables from document
   */
  extract_tables?: boolean;
  /**
   * Extract images from document
   */
  extract_images?: boolean;
  /**
   * Preserve text formatting
   */
  preserve_formatting?: boolean;
  /**
   * Include header and footer content
   */
  include_header_footer?: boolean;
}

/**
 * Advanced markdown parser using LlamaIndex with semantic chunking
 */
export interface MarkdownParserLlamaIndexConfiguration {
  /**
   * Chunk size in characters
   */
  chunk_size?: number;
  /**
   * Overlap between chunks
   */
  chunk_overlap?: number;
  /**
   * Chunking strategy for markdown
   */
  chunk_strategy?: 'headings' | 'paragraphs' | 'sentences' | 'semantic';
  /**
   * Extract frontmatter metadata
   */
  extract_metadata?: boolean;
  /**
   * Extract code blocks separately
   */
  extract_code_blocks?: boolean;
  /**
   * Extract markdown tables
   */
  extract_tables?: boolean;
  /**
   * Extract links and references
   */
  extract_links?: boolean;
  /**
   * Preserve heading hierarchy
   */
  preserve_structure?: boolean;
}

export interface MSGParserExtractMsgConfiguration {
  /**
   * Chunk size in characters
   */
  chunk_size?: number;
  /**
   * Overlap between chunks
   */
  chunk_overlap?: number;
  /**
   * Chunking strategy
   */
  chunk_strategy?: 'sentences' | 'paragraphs' | 'characters' | 'email_sections';
  /**
   * Extract metadata
   */
  extract_metadata?: boolean;
  /**
   * Extract attachments
   */
  extract_attachments?: boolean;
  /**
   * Extract headers
   */
  extract_headers?: boolean;
  /**
   * Include attachment content
   */
  include_attachment_content?: boolean;
  /**
   * Clean text
   */
  clean_text?: boolean;
  /**
   * Preserve formatting
   */
  preserve_formatting?: boolean;
  /**
   * Encoding
   */
  encoding?: string;
}

// ============================================================================
// Extractor Config Interfaces (generated by json-schema-to-typescript)
// ============================================================================

export interface KeywordExtractorConfiguration {
  /**
   * Extractor type discriminator
   */
  extractor_type?: 'keyword';
  /**
   * Extraction algorithm
   */
  algorithm?: 'rake' | 'yake' | 'tfidf' | 'textrank';
  /**
   * Maximum keywords to extract
   */
  max_keywords?: number;
  /**
   * Minimum word length for keywords
   */
  min_length?: number;
  /**
   * Maximum word length for keywords
   */
  max_length?: number;
  /**
   * Minimum frequency for keywords
   */
  min_frequency?: number;
  /**
   * Custom stop words
   */
  stop_words?: string[];
  /**
   * Language for YAKE algorithm
   */
  language?: string;
  /**
   * Maximum n-gram size for YAKE
   */
  max_ngram_size?: number;
  /**
   * Deduplication threshold for YAKE
   */
  deduplication_threshold?: number;
}

export interface EntityExtractorConfiguration {
  /**
   * NER model name
   */
  model?: string;
  /**
   * Entity types to extract
   */
  entity_types?: (
    | 'PERSON'
    | 'ORG'
    | 'GPE'
    | 'DATE'
    | 'TIME'
    | 'MONEY'
    | 'EMAIL'
    | 'PHONE'
    | 'URL'
    | 'LAW'
    | 'PERCENT'
    | 'PRODUCT'
    | 'EVENT'
    | 'VERSION'
    | 'FAC'
    | 'LOC'
  )[];
  /**
   * Use regex fallback
   */
  use_fallback?: boolean;
  /**
   * Minimum entity length
   */
  min_entity_length?: number;
  /**
   * Merge adjacent entities
   */
  merge_entities?: boolean;
  /**
   * Minimum confidence score
   */
  confidence_threshold?: number;
}

export interface DateTimeExtractorConfiguration {
  /**
   * Enable fuzzy parsing
   */
  fuzzy_parsing?: boolean;
  /**
   * Extract relative dates
   */
  extract_relative?: boolean;
  /**
   * Extract time expressions
   */
  extract_times?: boolean;
  /**
   * Extract durations
   */
  extract_durations?: boolean;
  /**
   * Default timezone
   */
  default_timezone?: string;
  /**
   * Output date format
   */
  date_format?: string;
  /**
   * Preference for ambiguous dates
   */
  prefer_dates_from?: 'past' | 'future' | 'current';
}

export interface HeadingExtractorConfiguration {
  /**
   * Maximum heading level
   */
  max_level?: number;
  /**
   * Include hierarchy structure
   */
  include_hierarchy?: boolean;
  /**
   * Generate document outline
   */
  extract_outline?: boolean;
  /**
   * Minimum heading length
   */
  min_heading_length?: number;
  /**
   * Enable this extractor
   */
  enabled?: boolean;
}

export interface LinkExtractorConfiguration {
  /**
   * Extract URLs
   */
  extract_urls?: boolean;
  /**
   * Extract email addresses
   */
  extract_emails?: boolean;
  /**
   * Extract unique domains
   */
  extract_domains?: boolean;
  /**
   * Validate URL format
   */
  validate_urls?: boolean;
  /**
   * Resolve URL redirects
   */
  resolve_redirects?: boolean;
  /**
   * Enable this extractor
   */
  enabled?: boolean;
}

export interface PathExtractorConfiguration {
  /**
   * Extract file paths
   */
  extract_file_paths?: boolean;
  /**
   * Extract URL paths
   */
  extract_urls?: boolean;
  /**
   * Extract S3 paths
   */
  extract_s3_paths?: boolean;
  /**
   * Validate path existence
   */
  validate_paths?: boolean;
  /**
   * Normalize path formats
   */
  normalize_paths?: boolean;
  /**
   * Enable this extractor
   */
  enabled?: boolean;
}

export interface PatternExtractorConfiguration {
  /**
   * Use built-in patterns for common data types (e.g., email, phone). Takes precedence over 'patterns' field for matching pattern names
   */
  predefined_patterns?: (
    | 'email'
    | 'phone'
    | 'url'
    | 'ip'
    | 'ip_address'
    | 'ssn'
    | 'credit_card'
    | 'zip_code'
    | 'file_path'
    | 'version'
    | 'date'
  )[];
  /**
   * Custom regex patterns
   */
  custom_patterns?: {
    /**
     * Pattern name
     */
    name: string;
    /**
     * Regex pattern
     */
    pattern: string;
    /**
     * Pattern description
     */
    description?: string;
  }[];
  /**
   * Case-sensitive matching
   */
  case_sensitive?: boolean;
  /**
   * Return match positions
   */
  return_positions?: boolean;
  /**
   * Include surrounding context in results
   */
  include_context?: boolean;
  /**
   * Maximum matches per pattern
   */
  max_matches_per_pattern?: number;
  /**
   * Remove duplicate matches
   */
  deduplicate_matches?: boolean;
}

export interface StatisticsExtractorConfiguration {
  /**
   * Calculate readability scores
   */
  include_readability?: boolean;
  /**
   * Analyze vocabulary
   */
  include_vocabulary?: boolean;
  /**
   * Analyze text structure
   */
  include_structure?: boolean;
  /**
   * Basic sentiment analysis
   */
  include_sentiment?: boolean;
  /**
   * Include detailed sentiment indicators
   */
  include_sentiment_indicators?: boolean;
  /**
   * Detect language
   */
  include_language?: boolean;
}

export interface SummaryExtractorConfiguration {
  /**
   * Number of summary sentences
   */
  summary_sentences?: number;
  /**
   * Summarization algorithm
   */
  algorithm?: 'textrank' | 'lsa' | 'luhn' | 'lexrank';
  /**
   * Extract key phrases
   */
  include_key_phrases?: boolean;
  /**
   * Include text statistics
   */
  include_statistics?: boolean;
  /**
   * Minimum sentence length for summary
   */
  min_sentence_length?: number;
  /**
   * Maximum sentence length for summary
   */
  max_sentence_length?: number;
}

export interface SentimentExtractorConfiguration {
  /**
   * Analyze business-specific tone
   */
  analyze_business_tone?: boolean;
  /**
   * Extract confidence scores
   */
  extract_confidence?: boolean;
  /**
   * Sentiment categories to analyze
   */
  categories?: ('positive' | 'negative' | 'neutral' | 'mixed')[];
}

export interface YAKEExtractorConfiguration {
  /**
   * Extractor type discriminator
   */
  extractor_type?: 'yake';
  /**
   * Maximum keywords to extract
   */
  max_keywords?: number;
  /**
   * Language for YAKE algorithm
   */
  language?: string;
  /**
   * Maximum n-gram size for YAKE
   */
  max_ngram_size?: number;
  /**
   * Deduplication threshold for YAKE
   */
  deduplication_threshold?: number;
}

export interface ContentStatisticsExtractorConfiguration {
  /**
   * Calculate readability scores
   */
  include_readability?: boolean;
  /**
   * Analyze vocabulary
   */
  include_vocabulary?: boolean;
  /**
   * Analyze text structure
   */
  include_structure?: boolean;
  /**
   * Include detailed sentiment indicators
   */
  include_sentiment_indicators?: boolean;
}

export interface TableExtractorConfiguration {
  /**
   * Output format
   */
  output_format?: 'dict' | 'list' | 'csv' | 'markdown';
  /**
   * Extract table headers
   */
  extract_headers?: boolean;
  /**
   * Handle merged cells
   */
  merge_cells?: boolean;
  /**
   * Minimum rows for table
   */
  min_rows?: number;
  /**
   * Enable this extractor
   */
  enabled?: boolean;
}

// ============================================================================
// Type Constants
// ============================================================================

export const PARSER_TYPES = ["CSVParser_LlamaIndex","CSVParser_Pandas","CSVParser_Python","DocxParser_LlamaIndex","DocxParser_PythonDocx","ExcelParser_LlamaIndex","ExcelParser_OpenPyXL","ExcelParser_Pandas","MSGParser_ExtractMsg","MarkdownParser_LlamaIndex","MarkdownParser_Python","PDFParser_LlamaIndex","PDFParser_PyPDF2","TextParser_LlamaIndex","TextParser_Python","auto"] as const
export type ParserType = typeof PARSER_TYPES[number]

export const EXTRACTOR_TYPES = ["ContentStatisticsExtractor","DateTimeExtractor","EntityExtractor","HeadingExtractor","KeywordExtractor","LinkExtractor","PathExtractor","PatternExtractor","RAKEExtractor","SummaryExtractor","TFIDFExtractor","TableExtractor","YAKEExtractor"] as const
export type ExtractorType = typeof EXTRACTOR_TYPES[number]

// ============================================================================
// Helper Types for UI Forms
// ============================================================================

export interface SchemaField {
  type?: string
  title?: string
  description?: string
  default?: unknown
  minimum?: number
  maximum?: number
  enum?: string[]
  items?: { type?: string }
  nullable?: boolean
}

export interface ParserSchema {
  properties: Record<string, SchemaField>
  title: string
  description: string
  defaultExtensions?: string[]
}

export interface ExtractorSchema {
  properties: Record<string, SchemaField>
  title: string
  description: string
}

/**
 * Schema metadata indexed by ParserType (e.g., "PDFParser_PyPDF2")
 * Dynamically generated from rag/schema.yaml - no hardcoding needed.
 */
export const PARSER_SCHEMAS = {
  "auto": {
    "properties": {
      "chunk_size": {
        "type": "integer",
        "default": 1000,
        "minimum": 100,
        "maximum": 10000,
        "description": "Chunk size for text splitting"
      },
      "chunk_overlap": {
        "type": "integer",
        "default": 200,
        "minimum": 0,
        "maximum": 500,
        "description": "Overlap between chunks"
      }
    },
    "title": "Auto Parser Configuration",
    "description": "",
    "defaultExtensions": []
  },
  "PDFParser_PyPDF2": {
    "properties": {
      "chunk_size": {
        "type": "integer",
        "default": 1000,
        "minimum": 100,
        "maximum": 50000,
        "description": "Chunk size in characters"
      },
      "chunk_overlap": {
        "type": "integer",
        "default": 100,
        "minimum": 0,
        "maximum": 5000,
        "description": "Overlap between chunks in characters"
      },
      "chunk_strategy": {
        "type": "string",
        "enum": [
          "paragraphs",
          "sentences",
          "characters"
        ],
        "default": "paragraphs",
        "description": "Chunking strategy using PyPDF2 text structure"
      },
      "extract_metadata": {
        "type": "boolean",
        "default": true,
        "description": "Extract PDF metadata using PyPDF2"
      },
      "preserve_layout": {
        "type": "boolean",
        "default": true,
        "description": "Use PyPDF2 layout-preserving extraction mode"
      },
      "extract_page_info": {
        "type": "boolean",
        "default": true,
        "description": "Extract page numbers and rotation info"
      },
      "extract_annotations": {
        "type": "boolean",
        "default": false,
        "description": "Extract PDF annotations using PyPDF2"
      },
      "extract_links": {
        "type": "boolean",
        "default": false,
        "description": "Extract hyperlinks"
      },
      "extract_form_fields": {
        "type": "boolean",
        "default": false,
        "description": "Extract form fields using PyPDF2"
      },
      "extract_outlines": {
        "type": "boolean",
        "default": false,
        "description": "Extract document outlines/bookmarks"
      },
      "extract_images": {
        "type": "boolean",
        "default": false,
        "description": "Extract embedded images using PyPDF2"
      },
      "extract_xmp_metadata": {
        "type": "boolean",
        "default": false,
        "description": "Extract XMP metadata using PyPDF2"
      },
      "clean_text": {
        "type": "boolean",
        "default": true,
        "description": "Clean extracted text"
      },
      "combine_pages": {
        "type": "boolean",
        "default": false,
        "description": "Combine all pages into a single document. MUST be false to enable chunking."
      }
    },
    "title": "PDF Parser (PyPDF2) Configuration",
    "description": "Enhanced PDF parser using PyPDF2 with comprehensive capabilities",
    "defaultExtensions": [
      ".pdf"
    ]
  },
  "CSVParser_Pandas": {
    "properties": {
      "chunk_size": {
        "type": "integer",
        "default": 1000,
        "minimum": 100,
        "description": "Number of rows per chunk"
      },
      "chunk_strategy": {
        "type": "string",
        "enum": [
          "rows",
          "columns",
          "full"
        ],
        "default": "rows",
        "description": "How to chunk the CSV data"
      },
      "extract_metadata": {
        "type": "boolean",
        "default": true,
        "description": "Extract data statistics and metadata"
      },
      "encoding": {
        "type": "string",
        "default": "utf-8",
        "description": "File encoding"
      },
      "delimiter": {
        "type": "string",
        "default": ",",
        "description": "CSV delimiter"
      },
      "na_values": {
        "type": "array",
        "items": {
          "type": "string"
        },
        "default": [
          "",
          "NA",
          "N/A",
          "null",
          "None"
        ],
        "description": "Values to treat as NaN"
      }
    },
    "title": "CSV Parser (Pandas) Configuration",
    "description": "Advanced CSV parser using Pandas with data analysis capabilities",
    "defaultExtensions": [
      ".csv"
    ]
  },
  "CSVParser_Python": {
    "properties": {
      "chunk_size": {
        "type": "integer",
        "default": 1000,
        "minimum": 100,
        "description": "Number of rows per chunk"
      },
      "encoding": {
        "type": "string",
        "default": "utf-8",
        "description": "File encoding"
      },
      "delimiter": {
        "type": "string",
        "default": ",",
        "description": "CSV delimiter"
      },
      "quotechar": {
        "type": "string",
        "default": "\"",
        "description": "Quote character"
      }
    },
    "title": "CSV Parser (Python) Configuration",
    "description": "Simple CSV parser using native Python csv module",
    "defaultExtensions": [
      ".csv"
    ]
  },
  "ExcelParser_OpenPyXL": {
    "properties": {
      "chunk_size": {
        "type": "integer",
        "default": 1000,
        "minimum": 100,
        "description": "Number of rows per chunk"
      },
      "extract_formulas": {
        "type": "boolean",
        "default": false,
        "description": "Extract cell formulas using OpenPyXL"
      },
      "extract_metadata": {
        "type": "boolean",
        "default": true,
        "description": "Extract workbook metadata"
      },
      "sheets": {
        "type": [
          "array",
          "null"
        ],
        "items": {
          "type": "string"
        },
        "default": null,
        "description": "Specific sheets to process (null = all)"
      },
      "data_only": {
        "type": "boolean",
        "default": true,
        "description": "Extract values instead of formulas"
      }
    },
    "title": "Excel Parser (OpenPyXL) Configuration",
    "description": "Excel parser using OpenPyXL for XLSX files with formula support",
    "defaultExtensions": [
      ".xlsx",
      ".xls"
    ]
  },
  "ExcelParser_Pandas": {
    "properties": {
      "chunk_size": {
        "type": "integer",
        "default": 1000,
        "minimum": 100,
        "description": "Number of rows per chunk"
      },
      "sheets": {
        "type": [
          "array",
          "null"
        ],
        "items": {
          "type": "string"
        },
        "default": null,
        "description": "Specific sheets to process (null = all)"
      },
      "extract_metadata": {
        "type": "boolean",
        "default": true,
        "description": "Extract data statistics"
      },
      "skiprows": {
        "type": [
          "integer",
          "null"
        ],
        "default": null,
        "description": "Rows to skip at beginning"
      },
      "na_values": {
        "type": "array",
        "items": {
          "type": "string"
        },
        "default": [
          "",
          "NA",
          "N/A",
          "null",
          "None"
        ],
        "description": "Values to treat as NaN"
      }
    },
    "title": "Excel Parser (Pandas) Configuration",
    "description": "Excel parser using Pandas with data analysis capabilities",
    "defaultExtensions": [
      ".xlsx",
      ".xls"
    ]
  },
  "DocxParser_PythonDocx": {
    "properties": {
      "chunk_size": {
        "type": "integer",
        "default": 1000,
        "minimum": 100,
        "description": "Chunk size in characters"
      },
      "chunk_strategy": {
        "type": "string",
        "enum": [
          "paragraphs",
          "sentences",
          "characters"
        ],
        "default": "paragraphs",
        "description": "Chunking strategy"
      },
      "extract_metadata": {
        "type": "boolean",
        "default": true,
        "description": "Extract document metadata"
      },
      "extract_tables": {
        "type": "boolean",
        "default": true,
        "description": "Extract tables using python-docx"
      },
      "extract_headers": {
        "type": "boolean",
        "default": true,
        "description": "Extract headers"
      },
      "extract_footers": {
        "type": "boolean",
        "default": false,
        "description": "Extract footers"
      },
      "extract_comments": {
        "type": "boolean",
        "default": false,
        "description": "Extract comments"
      }
    },
    "title": "DOCX Parser (python-docx) Configuration",
    "description": "Word document parser using python-docx library",
    "defaultExtensions": [
      ".docx"
    ]
  },
  "MarkdownParser_Python": {
    "properties": {
      "chunk_size": {
        "type": "integer",
        "default": 1000,
        "minimum": 100,
        "description": "Chunk size in characters"
      },
      "chunk_strategy": {
        "type": "string",
        "enum": [
          "sections",
          "paragraphs",
          "characters"
        ],
        "default": "sections",
        "description": "Chunking strategy - sections uses markdown headers"
      },
      "extract_metadata": {
        "type": "boolean",
        "default": true,
        "description": "Extract YAML frontmatter"
      },
      "extract_code_blocks": {
        "type": "boolean",
        "default": true,
        "description": "Extract code blocks"
      },
      "extract_links": {
        "type": "boolean",
        "default": true,
        "description": "Extract markdown links"
      }
    },
    "title": "Markdown Parser (Python) Configuration",
    "description": "Markdown parser using native Python with regex parsing",
    "defaultExtensions": [
      ".md",
      ".markdown"
    ]
  },
  "TextParser_Python": {
    "properties": {
      "chunk_size": {
        "type": "integer",
        "default": 1000,
        "minimum": 100,
        "description": "Chunk size in characters"
      },
      "chunk_overlap": {
        "type": "integer",
        "default": 100,
        "minimum": 0,
        "description": "Overlap between chunks"
      },
      "chunk_strategy": {
        "type": "string",
        "enum": [
          "sentences",
          "paragraphs",
          "characters"
        ],
        "default": "sentences",
        "description": "Text chunking strategy"
      },
      "encoding": {
        "type": "string",
        "default": "utf-8",
        "description": "Text encoding (utf-8 or auto-detect)"
      },
      "clean_text": {
        "type": "boolean",
        "default": true,
        "description": "Remove excessive whitespace"
      },
      "extract_metadata": {
        "type": "boolean",
        "default": true,
        "description": "Extract file statistics"
      }
    },
    "title": "Text Parser (Python) Configuration",
    "description": "Text parser using native Python with encoding detection",
    "defaultExtensions": [
      ".txt"
    ]
  },
  "TextParser_LlamaIndex": {
    "properties": {
      "chunk_size": {
        "type": "integer",
        "default": 1000,
        "minimum": 100,
        "maximum": 50000,
        "description": "Chunk size in characters"
      },
      "chunk_overlap": {
        "type": "integer",
        "default": 100,
        "minimum": 0,
        "maximum": 5000,
        "description": "Overlap between chunks"
      },
      "chunk_strategy": {
        "type": "string",
        "enum": [
          "characters",
          "sentences",
          "paragraphs",
          "tokens",
          "semantic",
          "code"
        ],
        "default": "semantic",
        "description": "Advanced chunking strategy - semantic uses content-based splitting, code preserves syntax"
      },
      "encoding": {
        "type": "string",
        "default": "utf-8",
        "description": "Text encoding"
      },
      "clean_text": {
        "type": "boolean",
        "default": true,
        "description": "Clean extracted text"
      },
      "extract_metadata": {
        "type": "boolean",
        "default": true,
        "description": "Extract comprehensive file and content metadata"
      },
      "semantic_buffer_size": {
        "type": "integer",
        "default": 1,
        "minimum": 1,
        "maximum": 10,
        "description": "Buffer size for semantic chunking"
      },
      "semantic_breakpoint_percentile_threshold": {
        "type": "integer",
        "default": 95,
        "minimum": 50,
        "maximum": 99,
        "description": "Percentile threshold for semantic breakpoints"
      },
      "token_model": {
        "type": "string",
        "default": "gpt-3.5-turbo",
        "description": "Tokenizer model for token-based chunking"
      },
      "preserve_code_structure": {
        "type": "boolean",
        "default": true,
        "description": "Preserve code syntax and structure when parsing code files"
      },
      "detect_language": {
        "type": "boolean",
        "default": true,
        "description": "Automatically detect programming language for code files"
      },
      "include_prev_next_rel": {
        "type": "boolean",
        "default": true,
        "description": "Include relationships between chunks for better context"
      }
    },
    "title": "Text Parser (LlamaIndex) Configuration",
    "description": "Advanced text parser using LlamaIndex with semantic splitting, code parsing, and multi-format support",
    "defaultExtensions": [
      ".txt"
    ]
  },
  "PDFParser_LlamaIndex": {
    "properties": {
      "chunk_size": {
        "type": "integer",
        "default": 1000,
        "minimum": 100,
        "maximum": 50000,
        "description": "Chunk size in characters"
      },
      "chunk_overlap": {
        "type": "integer",
        "default": 100,
        "minimum": 0,
        "maximum": 5000,
        "description": "Overlap between chunks"
      },
      "chunk_strategy": {
        "type": "string",
        "enum": [
          "sentences",
          "paragraphs",
          "pages",
          "semantic"
        ],
        "default": "sentences",
        "description": "Chunking strategy for PDF content"
      },
      "extract_metadata": {
        "type": "boolean",
        "default": true,
        "description": "Extract PDF metadata"
      },
      "extract_images": {
        "type": "boolean",
        "default": false,
        "description": "Extract images from PDF"
      },
      "extract_tables": {
        "type": "boolean",
        "default": true,
        "description": "Extract tables from PDF"
      },
      "fallback_strategies": {
        "type": "array",
        "items": {
          "type": "string",
          "enum": [
            "llama_pdf_reader",
            "llama_pymupdf_reader",
            "direct_pymupdf",
            "pypdf2_fallback"
          ]
        },
        "default": [
          "llama_pdf_reader",
          "llama_pymupdf_reader",
          "direct_pymupdf",
          "pypdf2_fallback"
        ],
        "description": "Fallback strategies to try in order"
      }
    },
    "title": "PDF Parser (LlamaIndex) Configuration",
    "description": "Advanced PDF parser using LlamaIndex with multiple fallback strategies",
    "defaultExtensions": [
      ".pdf"
    ]
  },
  "CSVParser_LlamaIndex": {
    "properties": {
      "chunk_size": {
        "type": "integer",
        "default": 1000,
        "minimum": 100,
        "maximum": 50000,
        "description": "Number of rows per chunk"
      },
      "chunk_strategy": {
        "type": "string",
        "enum": [
          "rows",
          "semantic",
          "full"
        ],
        "default": "rows",
        "description": "Chunking strategy"
      },
      "field_mapping": {
        "type": "object",
        "additionalProperties": {
          "type": "string"
        },
        "description": "Map CSV columns to standard fields"
      },
      "extract_metadata": {
        "type": "boolean",
        "default": true,
        "description": "Extract metadata from CSV"
      },
      "combine_fields": {
        "type": "boolean",
        "default": true,
        "description": "Combine fields into text content"
      },
      "skiprows": {
        "type": "integer",
        "minimum": 0,
        "description": "Number of rows to skip at beginning"
      },
      "na_values": {
        "type": "array",
        "items": {
          "type": "string"
        },
        "default": [
          "",
          "NA",
          "N/A",
          "null",
          "None"
        ],
        "description": "Values to treat as missing"
      }
    },
    "title": "CSV Parser (LlamaIndex) Configuration",
    "description": "CSV parser using LlamaIndex with Pandas backend for advanced processing",
    "defaultExtensions": [
      ".csv"
    ]
  },
  "ExcelParser_LlamaIndex": {
    "properties": {
      "chunk_size": {
        "type": "integer",
        "default": 1000,
        "minimum": 100,
        "maximum": 50000,
        "description": "Number of rows per chunk"
      },
      "chunk_strategy": {
        "type": "string",
        "enum": [
          "rows",
          "semantic",
          "full"
        ],
        "default": "rows",
        "description": "Chunking strategy"
      },
      "sheets": {
        "type": [
          "array",
          "null"
        ],
        "items": {
          "type": "string"
        },
        "description": "Specific sheets to parse (null for all)"
      },
      "combine_sheets": {
        "type": "boolean",
        "default": false,
        "description": "Combine all sheets into one document"
      },
      "extract_metadata": {
        "type": "boolean",
        "default": true,
        "description": "Extract metadata from Excel"
      },
      "extract_formulas": {
        "type": "boolean",
        "default": false,
        "description": "Extract formulas instead of values"
      },
      "header_row": {
        "type": "integer",
        "default": 0,
        "minimum": 0,
        "description": "Row index for headers"
      },
      "skiprows": {
        "type": "integer",
        "minimum": 0,
        "description": "Number of rows to skip"
      },
      "na_values": {
        "type": "array",
        "items": {
          "type": "string"
        },
        "default": [
          "",
          "NA",
          "N/A",
          "null",
          "None"
        ],
        "description": "Values to treat as missing"
      }
    },
    "title": "Excel Parser (LlamaIndex) Configuration",
    "description": "Excel parser using LlamaIndex with Pandas backend for advanced processing",
    "defaultExtensions": [
      ".xlsx",
      ".xls"
    ]
  },
  "DocxParser_LlamaIndex": {
    "properties": {
      "chunk_size": {
        "type": "integer",
        "default": 1000,
        "minimum": 100,
        "maximum": 50000,
        "description": "Chunk size in characters"
      },
      "chunk_overlap": {
        "type": "integer",
        "default": 100,
        "minimum": 0,
        "maximum": 5000,
        "description": "Overlap between chunks"
      },
      "chunk_strategy": {
        "type": "string",
        "enum": [
          "paragraphs",
          "sentences",
          "semantic"
        ],
        "default": "paragraphs",
        "description": "Chunking strategy"
      },
      "extract_metadata": {
        "type": "boolean",
        "default": true,
        "description": "Extract document metadata"
      },
      "extract_tables": {
        "type": "boolean",
        "default": true,
        "description": "Extract tables from document"
      },
      "extract_images": {
        "type": "boolean",
        "default": false,
        "description": "Extract images from document"
      },
      "preserve_formatting": {
        "type": "boolean",
        "default": true,
        "description": "Preserve text formatting"
      },
      "include_header_footer": {
        "type": "boolean",
        "default": false,
        "description": "Include header and footer content"
      }
    },
    "title": "DOCX Parser (LlamaIndex) Configuration",
    "description": "Advanced DOCX parser using LlamaIndex with enhanced chunking",
    "defaultExtensions": [
      ".docx"
    ]
  },
  "MarkdownParser_LlamaIndex": {
    "properties": {
      "chunk_size": {
        "type": "integer",
        "default": 1000,
        "minimum": 100,
        "maximum": 50000,
        "description": "Chunk size in characters"
      },
      "chunk_overlap": {
        "type": "integer",
        "default": 100,
        "minimum": 0,
        "maximum": 5000,
        "description": "Overlap between chunks"
      },
      "chunk_strategy": {
        "type": "string",
        "enum": [
          "headings",
          "paragraphs",
          "sentences",
          "semantic"
        ],
        "default": "headings",
        "description": "Chunking strategy for markdown"
      },
      "extract_metadata": {
        "type": "boolean",
        "default": true,
        "description": "Extract frontmatter metadata"
      },
      "extract_code_blocks": {
        "type": "boolean",
        "default": true,
        "description": "Extract code blocks separately"
      },
      "extract_tables": {
        "type": "boolean",
        "default": true,
        "description": "Extract markdown tables"
      },
      "extract_links": {
        "type": "boolean",
        "default": true,
        "description": "Extract links and references"
      },
      "preserve_structure": {
        "type": "boolean",
        "default": true,
        "description": "Preserve heading hierarchy"
      }
    },
    "title": "Markdown Parser (LlamaIndex) Configuration",
    "description": "Advanced markdown parser using LlamaIndex with semantic chunking",
    "defaultExtensions": [
      ".md",
      ".markdown"
    ]
  },
  "MSGParser_ExtractMsg": {
    "properties": {
      "chunk_size": {
        "type": "integer",
        "default": 1000,
        "minimum": 100,
        "maximum": 50000,
        "description": "Chunk size in characters"
      },
      "chunk_overlap": {
        "type": "integer",
        "default": 100,
        "minimum": 0,
        "maximum": 5000,
        "description": "Overlap between chunks"
      },
      "chunk_strategy": {
        "type": "string",
        "enum": [
          "sentences",
          "paragraphs",
          "characters",
          "email_sections"
        ],
        "default": "email_sections",
        "description": "Chunking strategy"
      },
      "extract_metadata": {
        "type": "boolean",
        "default": true,
        "description": "Extract metadata"
      },
      "extract_attachments": {
        "type": "boolean",
        "default": true,
        "description": "Extract attachments"
      },
      "extract_headers": {
        "type": "boolean",
        "default": true,
        "description": "Extract headers"
      },
      "include_attachment_content": {
        "type": "boolean",
        "default": true,
        "description": "Include attachment content"
      },
      "clean_text": {
        "type": "boolean",
        "default": true,
        "description": "Clean text"
      },
      "preserve_formatting": {
        "type": "boolean",
        "default": false,
        "description": "Preserve formatting"
      },
      "encoding": {
        "type": "string",
        "default": "utf-8",
        "description": "Encoding"
      }
    },
    "title": "MSG Parser (extract-msg) Configuration",
    "description": "",
    "defaultExtensions": [
      ".msg"
    ]
  }
} as any

/**
 * Schema metadata indexed by ExtractorType (e.g., "KeywordExtractor")
 * Dynamically generated from rag/schema.yaml - no hardcoding needed.
 */
export const EXTRACTOR_SCHEMAS = {
  "ContentStatisticsExtractor": {
    "properties": {
      "include_readability": {
        "type": "boolean",
        "default": true,
        "description": "Calculate readability scores"
      },
      "include_vocabulary": {
        "type": "boolean",
        "default": true,
        "description": "Analyze vocabulary"
      },
      "include_structure": {
        "type": "boolean",
        "default": true,
        "description": "Analyze text structure"
      },
      "include_sentiment_indicators": {
        "type": "boolean",
        "default": false,
        "description": "Include detailed sentiment indicators"
      }
    },
    "title": "Content Statistics Extractor Configuration",
    "description": ""
  },
  "DateTimeExtractor": {
    "properties": {
      "fuzzy_parsing": {
        "type": "boolean",
        "default": true,
        "description": "Enable fuzzy parsing"
      },
      "extract_relative": {
        "type": "boolean",
        "default": true,
        "description": "Extract relative dates"
      },
      "extract_times": {
        "type": "boolean",
        "default": true,
        "description": "Extract time expressions"
      },
      "extract_durations": {
        "type": "boolean",
        "default": true,
        "description": "Extract durations"
      },
      "default_timezone": {
        "type": "string",
        "default": "UTC",
        "description": "Default timezone"
      },
      "date_format": {
        "type": "string",
        "default": "ISO",
        "description": "Output date format"
      },
      "prefer_dates_from": {
        "type": "string",
        "enum": [
          "past",
          "future",
          "current"
        ],
        "default": "current",
        "description": "Preference for ambiguous dates"
      }
    },
    "title": "DateTime Extractor Configuration",
    "description": ""
  },
  "EntityExtractor": {
    "properties": {
      "model": {
        "type": "string",
        "default": "en_core_web_sm",
        "description": "NER model name"
      },
      "entity_types": {
        "type": "array",
        "items": {
          "type": "string",
          "enum": [
            "PERSON",
            "ORG",
            "GPE",
            "DATE",
            "TIME",
            "MONEY",
            "EMAIL",
            "PHONE",
            "URL",
            "LAW",
            "PERCENT",
            "PRODUCT",
            "EVENT",
            "VERSION",
            "FAC",
            "LOC"
          ]
        },
        "default": [
          "PERSON",
          "ORG",
          "GPE",
          "DATE",
          "TIME",
          "MONEY",
          "EMAIL",
          "PHONE",
          "URL",
          "PERCENT",
          "PRODUCT",
          "EVENT"
        ],
        "description": "Entity types to extract"
      },
      "use_fallback": {
        "type": "boolean",
        "default": true,
        "description": "Use regex fallback"
      },
      "min_entity_length": {
        "type": "integer",
        "default": 2,
        "minimum": 1,
        "description": "Minimum entity length"
      },
      "merge_entities": {
        "type": "boolean",
        "default": true,
        "description": "Merge adjacent entities"
      },
      "confidence_threshold": {
        "type": "number",
        "default": 0.7,
        "minimum": 0,
        "maximum": 1,
        "description": "Minimum confidence score"
      }
    },
    "title": "Entity Extractor Configuration",
    "description": ""
  },
  "HeadingExtractor": {
    "properties": {
      "max_level": {
        "type": "integer",
        "default": 6,
        "minimum": 1,
        "maximum": 6,
        "description": "Maximum heading level"
      },
      "include_hierarchy": {
        "type": "boolean",
        "default": true,
        "description": "Include hierarchy structure"
      },
      "extract_outline": {
        "type": "boolean",
        "default": true,
        "description": "Generate document outline"
      },
      "min_heading_length": {
        "type": "integer",
        "default": 3,
        "minimum": 1,
        "description": "Minimum heading length"
      },
      "enabled": {
        "type": "boolean",
        "default": true,
        "description": "Enable this extractor"
      }
    },
    "title": "Heading Extractor Configuration",
    "description": ""
  },
  "KeywordExtractor": {
    "properties": {
      "extractor_type": {
        "type": "string",
        "const": "keyword",
        "description": "Extractor type discriminator"
      },
      "algorithm": {
        "type": "string",
        "enum": [
          "rake",
          "yake",
          "tfidf",
          "textrank"
        ],
        "default": "rake",
        "description": "Extraction algorithm"
      },
      "max_keywords": {
        "type": "integer",
        "default": 10,
        "minimum": 1,
        "maximum": 100,
        "description": "Maximum keywords to extract"
      },
      "min_length": {
        "type": "integer",
        "default": 1,
        "minimum": 1,
        "description": "Minimum word length for keywords"
      },
      "max_length": {
        "type": "integer",
        "default": 4,
        "minimum": 1,
        "description": "Maximum word length for keywords"
      },
      "min_frequency": {
        "type": "integer",
        "default": 1,
        "minimum": 1,
        "description": "Minimum frequency for keywords"
      },
      "stop_words": {
        "type": "array",
        "items": {
          "type": "string"
        },
        "description": "Custom stop words"
      },
      "language": {
        "type": "string",
        "default": "en",
        "description": "Language for YAKE algorithm"
      },
      "max_ngram_size": {
        "type": "integer",
        "default": 3,
        "minimum": 1,
        "maximum": 5,
        "description": "Maximum n-gram size for YAKE"
      },
      "deduplication_threshold": {
        "type": "number",
        "default": 0.9,
        "minimum": 0,
        "maximum": 1,
        "description": "Deduplication threshold for YAKE"
      }
    },
    "title": "Keyword Extractor Configuration",
    "description": ""
  },
  "LinkExtractor": {
    "properties": {
      "extract_urls": {
        "type": "boolean",
        "default": true,
        "description": "Extract URLs"
      },
      "extract_emails": {
        "type": "boolean",
        "default": true,
        "description": "Extract email addresses"
      },
      "extract_domains": {
        "type": "boolean",
        "default": true,
        "description": "Extract unique domains"
      },
      "validate_urls": {
        "type": "boolean",
        "default": false,
        "description": "Validate URL format"
      },
      "resolve_redirects": {
        "type": "boolean",
        "default": false,
        "description": "Resolve URL redirects"
      },
      "enabled": {
        "type": "boolean",
        "default": true,
        "description": "Enable this extractor"
      }
    },
    "title": "Link Extractor Configuration",
    "description": ""
  },
  "PathExtractor": {
    "properties": {
      "extract_file_paths": {
        "type": "boolean",
        "default": true,
        "description": "Extract file paths"
      },
      "extract_urls": {
        "type": "boolean",
        "default": true,
        "description": "Extract URL paths"
      },
      "extract_s3_paths": {
        "type": "boolean",
        "default": true,
        "description": "Extract S3 paths"
      },
      "validate_paths": {
        "type": "boolean",
        "default": false,
        "description": "Validate path existence"
      },
      "normalize_paths": {
        "type": "boolean",
        "default": true,
        "description": "Normalize path formats"
      },
      "enabled": {
        "type": "boolean",
        "default": true,
        "description": "Enable this extractor"
      }
    },
    "title": "Path Extractor Configuration",
    "description": ""
  },
  "PatternExtractor": {
    "properties": {
      "predefined_patterns": {
        "type": "array",
        "items": {
          "type": "string",
          "enum": [
            "email",
            "phone",
            "url",
            "ip",
            "ip_address",
            "ssn",
            "credit_card",
            "zip_code",
            "file_path",
            "version",
            "date"
          ]
        },
        "default": [],
        "description": "Use built-in patterns for common data types (e.g., email, phone). Takes precedence over 'patterns' field for matching pattern names"
      },
      "custom_patterns": {
        "type": "array",
        "items": {
          "type": "object",
          "required": [
            "name",
            "pattern"
          ],
          "additionalProperties": false,
          "properties": {
            "name": {
              "type": "string",
              "description": "Pattern name"
            },
            "pattern": {
              "type": "string",
              "description": "Regex pattern"
            },
            "description": {
              "type": "string",
              "description": "Pattern description"
            }
          }
        },
        "default": [],
        "description": "Custom regex patterns"
      },
      "case_sensitive": {
        "type": "boolean",
        "default": false,
        "description": "Case-sensitive matching"
      },
      "return_positions": {
        "type": "boolean",
        "default": false,
        "description": "Return match positions"
      },
      "include_context": {
        "type": "boolean",
        "default": false,
        "description": "Include surrounding context in results"
      },
      "max_matches_per_pattern": {
        "type": "integer",
        "default": 100,
        "minimum": 1,
        "description": "Maximum matches per pattern"
      },
      "deduplicate_matches": {
        "type": "boolean",
        "default": true,
        "description": "Remove duplicate matches"
      }
    },
    "title": "Pattern Extractor Configuration",
    "description": ""
  },
  "RAKEExtractor": {
    "properties": {
      "extractor_type": {
        "type": "string",
        "const": "keyword",
        "description": "Extractor type discriminator"
      },
      "algorithm": {
        "type": "string",
        "enum": [
          "rake",
          "yake",
          "tfidf",
          "textrank"
        ],
        "default": "rake",
        "description": "Extraction algorithm"
      },
      "max_keywords": {
        "type": "integer",
        "default": 10,
        "minimum": 1,
        "maximum": 100,
        "description": "Maximum keywords to extract"
      },
      "min_length": {
        "type": "integer",
        "default": 1,
        "minimum": 1,
        "description": "Minimum word length for keywords"
      },
      "max_length": {
        "type": "integer",
        "default": 4,
        "minimum": 1,
        "description": "Maximum word length for keywords"
      },
      "min_frequency": {
        "type": "integer",
        "default": 1,
        "minimum": 1,
        "description": "Minimum frequency for keywords"
      },
      "stop_words": {
        "type": "array",
        "items": {
          "type": "string"
        },
        "description": "Custom stop words"
      },
      "language": {
        "type": "string",
        "default": "en",
        "description": "Language for YAKE algorithm"
      },
      "max_ngram_size": {
        "type": "integer",
        "default": 3,
        "minimum": 1,
        "maximum": 5,
        "description": "Maximum n-gram size for YAKE"
      },
      "deduplication_threshold": {
        "type": "number",
        "default": 0.9,
        "minimum": 0,
        "maximum": 1,
        "description": "Deduplication threshold for YAKE"
      }
    },
    "title": "Keyword Extractor Configuration",
    "description": ""
  },
  "SummaryExtractor": {
    "properties": {
      "summary_sentences": {
        "type": "integer",
        "default": 3,
        "minimum": 1,
        "maximum": 10,
        "description": "Number of summary sentences"
      },
      "algorithm": {
        "type": "string",
        "enum": [
          "textrank",
          "lsa",
          "luhn",
          "lexrank"
        ],
        "default": "textrank",
        "description": "Summarization algorithm"
      },
      "include_key_phrases": {
        "type": "boolean",
        "default": true,
        "description": "Extract key phrases"
      },
      "include_statistics": {
        "type": "boolean",
        "default": true,
        "description": "Include text statistics"
      },
      "min_sentence_length": {
        "type": "integer",
        "default": 10,
        "minimum": 1,
        "description": "Minimum sentence length for summary"
      },
      "max_sentence_length": {
        "type": "integer",
        "default": 500,
        "minimum": 10,
        "description": "Maximum sentence length for summary"
      }
    },
    "title": "Summary Extractor Configuration",
    "description": ""
  },
  "TFIDFExtractor": {
    "properties": {
      "extractor_type": {
        "type": "string",
        "const": "keyword",
        "description": "Extractor type discriminator"
      },
      "algorithm": {
        "type": "string",
        "enum": [
          "rake",
          "yake",
          "tfidf",
          "textrank"
        ],
        "default": "rake",
        "description": "Extraction algorithm"
      },
      "max_keywords": {
        "type": "integer",
        "default": 10,
        "minimum": 1,
        "maximum": 100,
        "description": "Maximum keywords to extract"
      },
      "min_length": {
        "type": "integer",
        "default": 1,
        "minimum": 1,
        "description": "Minimum word length for keywords"
      },
      "max_length": {
        "type": "integer",
        "default": 4,
        "minimum": 1,
        "description": "Maximum word length for keywords"
      },
      "min_frequency": {
        "type": "integer",
        "default": 1,
        "minimum": 1,
        "description": "Minimum frequency for keywords"
      },
      "stop_words": {
        "type": "array",
        "items": {
          "type": "string"
        },
        "description": "Custom stop words"
      },
      "language": {
        "type": "string",
        "default": "en",
        "description": "Language for YAKE algorithm"
      },
      "max_ngram_size": {
        "type": "integer",
        "default": 3,
        "minimum": 1,
        "maximum": 5,
        "description": "Maximum n-gram size for YAKE"
      },
      "deduplication_threshold": {
        "type": "number",
        "default": 0.9,
        "minimum": 0,
        "maximum": 1,
        "description": "Deduplication threshold for YAKE"
      }
    },
    "title": "Keyword Extractor Configuration",
    "description": ""
  },
  "TableExtractor": {
    "properties": {
      "output_format": {
        "type": "string",
        "enum": [
          "dict",
          "list",
          "csv",
          "markdown"
        ],
        "default": "dict",
        "description": "Output format"
      },
      "extract_headers": {
        "type": "boolean",
        "default": true,
        "description": "Extract table headers"
      },
      "merge_cells": {
        "type": "boolean",
        "default": true,
        "description": "Handle merged cells"
      },
      "min_rows": {
        "type": "integer",
        "default": 2,
        "minimum": 1,
        "description": "Minimum rows for table"
      },
      "enabled": {
        "type": "boolean",
        "default": true,
        "description": "Enable this extractor"
      }
    },
    "title": "Table Extractor Configuration",
    "description": ""
  },
  "YAKEExtractor": {
    "properties": {
      "extractor_type": {
        "type": "string",
        "const": "keyword",
        "description": "Extractor type discriminator"
      },
      "algorithm": {
        "type": "string",
        "enum": [
          "rake",
          "yake",
          "tfidf",
          "textrank"
        ],
        "default": "rake",
        "description": "Extraction algorithm"
      },
      "max_keywords": {
        "type": "integer",
        "default": 10,
        "minimum": 1,
        "maximum": 100,
        "description": "Maximum keywords to extract"
      },
      "min_length": {
        "type": "integer",
        "default": 1,
        "minimum": 1,
        "description": "Minimum word length for keywords"
      },
      "max_length": {
        "type": "integer",
        "default": 4,
        "minimum": 1,
        "description": "Maximum word length for keywords"
      },
      "min_frequency": {
        "type": "integer",
        "default": 1,
        "minimum": 1,
        "description": "Minimum frequency for keywords"
      },
      "stop_words": {
        "type": "array",
        "items": {
          "type": "string"
        },
        "description": "Custom stop words"
      },
      "language": {
        "type": "string",
        "default": "en",
        "description": "Language for YAKE algorithm"
      },
      "max_ngram_size": {
        "type": "integer",
        "default": 3,
        "minimum": 1,
        "maximum": 5,
        "description": "Maximum n-gram size for YAKE"
      },
      "deduplication_threshold": {
        "type": "number",
        "default": 0.9,
        "minimum": 0,
        "maximum": 1,
        "description": "Deduplication threshold for YAKE"
      }
    },
    "title": "Keyword Extractor Configuration",
    "description": ""
  }
} as any

export function getDefaultParserConfig(parserType: ParserType): Record<string, any> {
  // Extract defaults from schema
  const schema = PARSER_SCHEMAS[parserType]
  if (!schema) return {}

  const defaults: Record<string, any> = {}
  for (const [key, field] of Object.entries(schema.properties as Record<string, SchemaField>)) {
    if (field && 'default' in field) {
      defaults[key] = field.default
    }
  }
  return defaults
}

export function getDefaultExtractorConfig(extractorType: ExtractorType): Record<string, any> {
  // Extract defaults from schema
  const schema = EXTRACTOR_SCHEMAS[extractorType]
  if (!schema) return {}

  const defaults: Record<string, any> = {}
  for (const [key, field] of Object.entries(schema.properties as Record<string, SchemaField>)) {
    if (field && 'default' in field) {
      defaults[key] = field.default
    }
  }
  return defaults
}
