# LlamaIndex Parser Strategies
# This file demonstrates the advanced capabilities of LlamaIndex parsers
# These parsers provide sophisticated chunking strategies and enhanced metadata extraction

strategies:
  # =============================================================================
  # ADVANCED PDF PROCESSING WITH LLAMAINDEX
  # =============================================================================
  - name: "advanced_pdf_processing"
    description: "Sophisticated PDF processing with LlamaIndex's multiple fallback strategies"
    tags: ["llamaindex", "pdf", "advanced", "fallback"]
    use_cases:
      - "Complex PDF documents with mixed content"
      - "Scanned documents requiring OCR"
      - "Research papers with citations and figures"
      - "Technical manuals with diagrams"
    
    components:
      parser:
        type: "PDFParser_LlamaIndex"
        config:
          chunk_size: 2000
          chunk_overlap: 300
          chunk_strategy: "semantic"  # Options: sentences, paragraphs, pages, semantic
          extract_metadata: true
          extract_images: true
          extract_tables: true
          # Multiple fallback strategies ensure robust parsing
          fallback_strategies:
            - "llama_pdf_reader"      # Primary LlamaIndex PDF reader
            - "llama_pymupdf_reader"  # PyMuPDF-based fallback
            - "direct_pymupdf"        # Direct PyMuPDF extraction
            - "pypdf2_fallback"       # Final fallback to PyPDF2
      
      extractors:
        - type: "TableExtractor"
          priority: 100
          config:
            output_format: "markdown"
            extract_headers: true
        
        - type: "CitationExtractor"
          priority: 95
          config:
            formats: ["APA", "MLA", "Chicago"]
        
        - type: "FigureExtractor"
          priority: 90
          config:
            extract_captions: true
            extract_references: true
      
      embedder:
        type: "OllamaEmbedder"
        config:
          model: "nomic-embed-text"
          batch_size: 4
          timeout: 90
      
      vector_store:
        type: "ChromaStore"
        config:
          collection_name: "advanced_pdf_documents"
          persist_directory: "./vectordb/advanced_pdf"
          distance_function: "cosine"
      
      retrieval_strategy:
        type: "RerankedStrategy"
        config:
          initial_top_k: 30
          final_top_k: 5
          rerank_factors:
            similarity_score: 0.5
            table_presence: 0.2
            figure_presence: 0.1
            recency: 0.1
            metadata_match: 0.1

  # =============================================================================
  # STRUCTURED MARKDOWN WITH LLAMAINDEX
  # =============================================================================
  - name: "structured_markdown_processing"
    description: "Heading-aware markdown processing preserving document structure"
    tags: ["llamaindex", "markdown", "structured", "documentation"]
    use_cases:
      - "Technical documentation with nested sections"
      - "API documentation with code examples"
      - "README files with installation guides"
      - "Tutorial content with step-by-step instructions"
    
    components:
      parser:
        type: "MarkdownParser_LlamaIndex"
        config:
          chunk_size: 1500
          chunk_overlap: 200
          chunk_strategy: "headings"  # Options: headings, paragraphs, sentences, semantic
          extract_metadata: true
          extract_code_blocks: true
          extract_tables: true
          extract_links: true
          preserve_structure: true  # Maintains heading hierarchy
      
      extractors:
        - type: "CodeExtractor"
          priority: 100
          config:
            languages: ["python", "javascript", "typescript", "bash", "yaml", "json"]
            extract_functions: true
            extract_classes: true
            extract_docstrings: true
        
        - type: "LinkExtractor"
          priority: 95
          config:
            extract_internal: true
            extract_external: true
            extract_anchors: true
            validate_urls: true
        
        - type: "TOCExtractor"
          priority: 90
          config:
            max_depth: 4
            include_anchors: true
      
      embedder:
        type: "OllamaEmbedder"
        config:
          model: "nomic-embed-text"
          batch_size: 5
          timeout: 60
      
      vector_store:
        type: "ChromaStore"
        config:
          collection_name: "structured_markdown"
          persist_directory: "./vectordb/markdown"
          distance_function: "cosine"
      
      retrieval_strategy:
        type: "HybridUniversalStrategy"
        config:
          strategies:
            - type: "BasicSimilarityStrategy"
              weight: 0.4
              config:
                top_k: 15
            - type: "MetadataFilteredStrategy"
              weight: 0.6
              config:
                top_k: 15
                filters:
                  - field: "heading_level"
                    operator: "lte"
                    value: 3
          aggregation_method: "weighted"
          final_top_k: 5

  # =============================================================================
  # MULTI-SHEET EXCEL ANALYSIS WITH LLAMAINDEX
  # =============================================================================
  - name: "multisheet_excel_analysis"
    description: "Advanced Excel processing with sheet relationships and formula extraction"
    tags: ["llamaindex", "excel", "data-analysis", "multi-sheet"]
    use_cases:
      - "Financial models with linked worksheets"
      - "Business reports with multiple data tables"
      - "Survey results with response analysis"
      - "Inventory tracking with cross-references"
    
    components:
      parser:
        type: "ExcelParser_LlamaIndex"
        config:
          chunk_size: 500  # Rows per chunk
          chunk_strategy: "rows"  # Options: rows, semantic, full
          sheets: null  # null = all sheets, or specify: ["Sheet1", "Summary"]
          combine_sheets: false  # Keep sheets separate for relationship analysis
          extract_metadata: true
          extract_formulas: true  # Preserve Excel formulas
          header_row: 0
          skiprows: null
          na_values: ["", "NA", "N/A", "null", "None", "#N/A", "#VALUE!", "#REF!"]
      
      extractors:
        - type: "TableExtractor"
          priority: 100
          config:
            output_format: "dataframe"
            extract_headers: true
            detect_merged_cells: true
        
        - type: "FormulaExtractor"
          priority: 95
          config:
            extract_dependencies: true
            extract_named_ranges: true
            validate_formulas: true
        
        - type: "StatisticsExtractor"
          priority: 90
          config:
            calculate_summary: true
            detect_outliers: true
            correlation_analysis: true
      
      embedder:
        type: "OllamaEmbedder"
        config:
          model: "nomic-embed-text"
          batch_size: 3
          timeout: 60
      
      vector_store:
        type: "ChromaStore"
        config:
          collection_name: "excel_analysis"
          persist_directory: "./vectordb/excel"
          distance_function: "cosine"
      
      retrieval_strategy:
        type: "MetadataFilteredStrategy"
        config:
          top_k: 15
          filter_mode: "pre"
          filters:
            - field: "sheet_name"
              operator: "in"
              value: ["Summary", "Analysis", "Results"]
          fallback_multiplier: 3

  # =============================================================================
  # INTELLIGENT CSV PROCESSING WITH LLAMAINDEX
  # =============================================================================
  - name: "intelligent_csv_processing"
    description: "Smart CSV parsing with field mapping and semantic understanding"
    tags: ["llamaindex", "csv", "data-processing", "pandas"]
    use_cases:
      - "Customer support ticket analysis"
      - "Sales data processing"
      - "Log file analysis"
      - "Survey response processing"
    
    components:
      parser:
        type: "CSVParser_LlamaIndex"
        config:
          chunk_size: 1000  # Rows per chunk
          chunk_strategy: "semantic"  # Options: rows, semantic, full
          field_mapping:
            # Map CSV columns to semantic fields
            "ticket_id": "id"
            "customer_email": "email"
            "issue_description": "content"
            "priority_level": "priority"
            "created_date": "timestamp"
          extract_metadata: true
          combine_fields: true  # Combine multiple fields into content
          skiprows: 0
          na_values: ["", "NA", "N/A", "null", "None", "nan"]
      
      extractors:
        - type: "EntityExtractor"
          priority: 100
          config:
            entity_types: ["EMAIL", "DATE", "PRODUCT", "PERSON", "ORG"]
            use_fallback: true
        
        - type: "SentimentExtractor"
          priority: 95
          config:
            analyze_per_row: true
            categories: ["positive", "negative", "neutral", "urgent"]
        
        - type: "CategoryClassifier"
          priority: 90
          config:
            categories: ["technical", "billing", "feature_request", "complaint"]
            multi_label: true
      
      embedder:
        type: "OllamaEmbedder"
        config:
          model: "nomic-embed-text"
          batch_size: 5
          timeout: 60
      
      vector_store:
        type: "ChromaStore"
        config:
          collection_name: "csv_data"
          persist_directory: "./vectordb/csv"
          distance_function: "cosine"
      
      retrieval_strategy:
        type: "MultiQueryStrategy"
        config:
          num_queries: 3
          aggregation_method: "reciprocal_rank_fusion"
          query_variations:
            - "original"
            - "entity_focused"
            - "sentiment_aware"
          top_k: 10

  # =============================================================================
  # DOCX DOCUMENT PROCESSING WITH LLAMAINDEX
  # =============================================================================
  - name: "docx_document_processing"
    description: "Enhanced DOCX parsing with style preservation and metadata extraction"
    tags: ["llamaindex", "docx", "word", "documents"]
    use_cases:
      - "Legal documents with specific formatting"
      - "Reports with embedded tables and images"
      - "Proposals with structured sections"
      - "Academic papers with citations"
    
    components:
      parser:
        type: "DocxParser_LlamaIndex"
        config:
          chunk_size: 1800
          chunk_overlap: 250
          chunk_strategy: "paragraphs"  # Options: paragraphs, sentences, semantic
          extract_metadata: true
          extract_tables: true
          extract_images: true
          preserve_formatting: true  # Keep bold, italic, underline
          include_header_footer: true
      
      extractors:
        - type: "StyleExtractor"
          priority: 100
          config:
            extract_headings: true
            extract_lists: true
            extract_quotes: true
        
        - type: "TableExtractor"
          priority: 95
          config:
            output_format: "html"
            preserve_formatting: true
        
        - type: "MetadataExtractor"
          priority: 90
          config:
            extract_author: true
            extract_creation_date: true
            extract_modification_date: true
            extract_word_count: true
      
      embedder:
        type: "OllamaEmbedder"
        config:
          model: "nomic-embed-text"
          batch_size: 4
          timeout: 60
      
      vector_store:
        type: "ChromaStore"
        config:
          collection_name: "docx_documents"
          persist_directory: "./vectordb/docx"
          distance_function: "cosine"
      
      retrieval_strategy:
        type: "RerankedStrategy"
        config:
          initial_top_k: 25
          final_top_k: 5
          rerank_factors:
            similarity_score: 0.5
            formatting_match: 0.2
            section_relevance: 0.2
            metadata_match: 0.1

  # =============================================================================
  # MULTI-FORMAT TEXT PROCESSING WITH LLAMAINDEX
  # =============================================================================
  - name: "multiformat_text_processing"
    description: "Universal text parser with language detection and code awareness"
    tags: ["llamaindex", "text", "multi-format", "code-aware"]
    use_cases:
      - "Source code documentation"
      - "Configuration file analysis"
      - "Log file processing"
      - "Mixed content documents"
    
    components:
      parser:
        type: "TextParser_LlamaIndex"
        config:
          chunk_size: 1500
          chunk_overlap: 150
          chunk_strategy: "semantic"  # Options: characters, sentences, paragraphs, tokens, semantic, code
          extract_metadata: true
          preserve_code_structure: true  # Keep code blocks intact
          detect_language: true  # Auto-detect programming language
          include_prev_next_rel: true  # Track chunk relationships
          semantic_breakpoint_percentile: 0.95
          token_model: "gpt-3.5-turbo"  # For token-based chunking
      
      extractors:
        - type: "CodeExtractor"
          priority: 100
          config:
            languages: ["python", "javascript", "java", "go", "rust", "cpp", "csharp"]
            extract_functions: true
            extract_classes: true
            extract_imports: true
            extract_comments: true
        
        - type: "PatternExtractor"
          priority: 95
          config:
            custom_patterns:
              - name: "ip_address"
                pattern: "\\b(?:[0-9]{1,3}\\.){3}[0-9]{1,3}\\b"
                description: "IPv4 addresses"
              - name: "error_code"
                pattern: "\\b[A-Z]{2,}_[A-Z0-9_]+\\b"
                description: "Error codes"
              - name: "version"
                pattern: "\\bv?\\d+\\.\\d+\\.\\d+\\b"
                description: "Version numbers"
        
        - type: "StructureExtractor"
          priority: 90
          config:
            detect_json: true
            detect_yaml: true
            detect_xml: true
            detect_ini: true
      
      embedder:
        type: "OllamaEmbedder"
        config:
          model: "nomic-embed-text"
          batch_size: 6
          timeout: 60
      
      vector_store:
        type: "ChromaStore"
        config:
          collection_name: "multiformat_text"
          persist_directory: "./vectordb/text"
          distance_function: "cosine"
      
      retrieval_strategy:
        type: "HybridUniversalStrategy"
        config:
          strategies:
            - type: "BasicSimilarityStrategy"
              weight: 0.3
              config:
                top_k: 20
            - type: "MetadataFilteredStrategy"
              weight: 0.4
              config:
                top_k: 20
                filters:
                  - field: "language"
                    operator: "eq"
                    value: "python"
            - type: "MultiQueryStrategy"
              weight: 0.3
              config:
                num_queries: 2
                top_k: 20
          aggregation_method: "weighted"
          final_top_k: 5

# Configuration Tips for LlamaIndex Parsers:
# 
# 1. Chunk Strategies:
#    - "semantic": Best for natural language with topic changes
#    - "headings": Ideal for structured documents (markdown, docx)
#    - "sentences": Good for maintaining complete thoughts
#    - "paragraphs": Preserves paragraph-level context
#    - "rows": For tabular data (CSV, Excel)
#    - "code": Respects code structure and syntax
#
# 2. Fallback Strategies (PDF):
#    - Multiple strategies ensure robust parsing
#    - Order matters - put most reliable first
#    - Each fallback handles different PDF types
#
# 3. Performance Optimization:
#    - Larger chunk_size = fewer chunks but more context
#    - Smaller chunk_overlap = less redundancy
#    - Semantic chunking is slower but more intelligent
#
# 4. Multi-Format Support:
#    - TextParser_LlamaIndex handles 30+ file extensions
#    - Auto-detects format and applies appropriate parsing
#    - Preserves format-specific features (code syntax, etc.)
#
# 5. Advanced Features:
#    - extract_metadata: Rich metadata extraction
#    - preserve_structure: Maintains document hierarchy
#    - include_prev_next_rel: Enables context-aware retrieval
#    - detect_language: Automatic programming language detection