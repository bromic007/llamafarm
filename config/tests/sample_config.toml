version = "v1"

name = "sample_config"
namespace = "test"

[[prompts]]
name = "default"
[[prompts.messages]]
role = "system"
content = "You are a helpful customer support assistant. Answer questions politely and accurately based on the provided context."

[[prompts]]
name = "technical_documentation"
[[prompts.messages]]
role = "system"
content = "You are a technical documentation assistant. Provide clear, accurate, and detailed explanations of technical concepts."

[[prompts]]
name = "code_review"
[[prompts.messages]]
role = "system"
content = "You are a code review assistant. Analyze code for best practices, potential bugs, and improvements."

[rag]

[[rag.databases]]
name = "support_db"
type = "ChromaStore"

[rag.databases.config]
collection_name = "customer_support_knowledge_base"
persist_directory = "./data/vector_store/chroma"

[[rag.databases.embedding_strategies]]
name = "default_embedding"
type = "OllamaEmbedder"

[rag.databases.embedding_strategies.config]
model = "mxbai-embed-large"
base_url = "http://localhost:11434"
batch_size = 32
timeout = 60
auto_pull = true

[[rag.databases.retrieval_strategies]]
name = "default_retrieval"
type = "BasicSimilarityStrategy"
default = true

[rag.databases.retrieval_strategies.config]
distance_metric = "cosine"

[[rag.data_processing_strategies]]
name = "default"
description = "Customer support strategy for testing"

[[rag.data_processing_strategies.parsers]]
type = "CSVParser_Pandas"
file_extensions = [".csv"]

[rag.data_processing_strategies.parsers.config]
content_fields = ["question", "answer", "solution", "explanation"]
metadata_fields = ["category", "timestamp", "priority", "tags", "author"]
id_field = "id"
combine_content = true
content_separator = "\n\n"

[[models]]
provider = "local"
model = "llama3.1:8b"

[[models]]
provider = "local"
model = "llama3.1:70b"

[[models]]
provider = "openai"
model = "gpt-4"

[[models]]
provider = "openai"
model = "gpt-4o-mini-turbo"

[[models]]
provider = "anthropic"
model = "claude-3-sonnet-20240229"

[[models]]
provider = "anthropic"
model = "claude-3-haiku-20240307"

[[models]]
provider = "google"
model = "gemini-pro"

[[models]]
provider = "custom"
model = "custom-fine-tuned-model-v1"

[[datasets]]
name = "sample_dataset"
data_processing_strategy = "default"
database = "support_db"
auto_process = true

[runtime]
provider = "openai"
model = "llama3.1:8b"
api_key = "ollama"
base_url = "http://localhost:11434/v1"
[runtime.model_api_parameters]
temperature = 0.5
