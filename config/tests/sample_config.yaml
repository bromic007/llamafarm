version: v1

name: sample_config
namespace: test

prompts:
  - role: "system"
    content: "You are a helpful customer support assistant. Answer questions politely and accurately based on the provided context."

rag:
  strategies:
    - name: "default"
      description: "Customer support strategy for testing"
      components:
        parser:
          type: "CSVParser_LlamaIndex"
          config:
            content_fields: ["question", "answer"]
            metadata_fields: ["category", "timestamp"]
            combine_content: true
            table_format: "markdown"
        extractors: []
        embedder:
          type: "OllamaEmbedder"
          config:
            model: "mxbai-embed-large"
            base_url: "http://localhost:11434"
            batch_size: 32
            timeout: 60
            auto_pull: true
        vector_store:
          type: "ChromaStore"
          config:
            collection_name: "customer_support_knowledge_base"
            persist_directory: "./data/vector_store/chroma"
        retrieval_strategy:
          type: "BasicSimilarityStrategy"
          config:
            distance_metric: "cosine"

datasets:
  - name: "sample_dataset"
    files: ["test_file.csv"]
    rag_strategy: "default"

runtime:
  provider: "openai"
  model: "llama3.1:8b"
  api_key: "ollama"
  base_url: "http://localhost:11434"
  model_api_parameters:
    temperature: 0.5
