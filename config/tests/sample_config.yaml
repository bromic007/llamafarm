version: v1

name: sample_config
namespace: test

prompts:
  - name: "default"
    messages:
      - role: "system"
        content: "You are a helpful customer support assistant. Answer questions politely and accurately based on the provided context."

rag:
  databases:
    - name: "support_db"
      type: "ChromaStore"
      config:
        collection_name: "customer_support_knowledge_base"
        persist_directory: "./data/vector_store/chroma"
      embedding_strategies:
        - name: "default_embedding"
          type: "OllamaEmbedder"
          config:
            model: "mxbai-embed-large"
            base_url: "http://localhost:11434"
            batch_size: 32
            timeout: 60
      retrieval_strategies:
        - name: "default_retrieval"
          type: "BasicSimilarityStrategy"
          config:
            distance_metric: "cosine"
          default: true
  data_processing_strategies:
    - name: "default"
      description: "Customer support strategy for testing"
      parsers:
        - type: "CSVParser_LlamaIndex"
          config:
            content_fields: ["question", "answer"]
            metadata_fields: ["category", "timestamp"]
            combine_content: true
            table_format: "markdown"
          file_extensions: [".csv"]
      extractors: []

datasets:
  - name: "sample_dataset"
    data_processing_strategy: "default"
    database: "support_db"
    auto_process: true

runtime:
  provider: "openai"
  model: "llama3.1:8b"
  api_key: "ollama"
  base_url: "http://localhost:11434"
  model_api_parameters:
    temperature: 0.5
