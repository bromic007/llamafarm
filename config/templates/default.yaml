version: v1
name: default-project
namespace: default
# `lf init` creates `schemas/` with `schemas/example.py` for structured outputs.
# Uncomment and point to your model class to enable:
# schema: schemas/example.py::Person

# =============================================================================
# RUNTIME CONFIGURATION
# =============================================================================
runtime:
  models:
    - name: default
      description: "Default Universal model"
      provider: universal
      model: unsloth/Qwen3-1.7B-GGUF:Q4_K_M
      default: true
      prompt_format: unstructured
      prompts: [default]

# =============================================================================
# PROMPTS CONFIGURATION
# =============================================================================
prompts:
  - name: default
    messages:
      - role: system
        content: |
          You are a helpful AI assistant.

          CRITICAL RULES:
          1. NEVER repeat the user's question as your answer
          2. ALWAYS provide a substantive, helpful response
          3. If you don't know something, say so clearly rather than repeating the question

          When RAG context is provided, use it to enhance your answers.
          When no context is available, use your general knowledge.

# =============================================================================
# DATASETS CONFIGURATION
# =============================================================================
datasets:
  - name: default
    database: main_database
    # Uses universal_rag strategy by default (no need to specify)
    auto_process: true

# =============================================================================
# RAG CONFIGURATION
# =============================================================================
rag:
  default_database: main_database

  # ---------------------------------------------------------------------------
  # DATABASE
  # ---------------------------------------------------------------------------
  databases:
    - name: main_database
      type: ChromaStore
      config:
        collection_name: documents

      embedding_strategies:
        - name: default_embeddings
          type: UniversalEmbedder
          priority: 0
          config:
            model: sentence-transformers/all-MiniLM-L6-v2
            dimension: 384
            batch_size: 16

      retrieval_strategies:
        - name: basic_search
          type: BasicSimilarityStrategy
          default: true
          config:
            top_k: 10

      default_embedding_strategy: default_embeddings
      default_retrieval_strategy: basic_search

  # ---------------------------------------------------------------------------
  # DATA PROCESSING STRATEGY (Optional - defaults to universal_rag if omitted)
  # ---------------------------------------------------------------------------
  # The universal_rag strategy works out-of-the-box with zero configuration.
  # Customize below if you need different chunking or extraction settings.
  #
  data_processing_strategies:
    - name: universal_rag
      description: "Universal processor for all document types"

      parsers:
        - type: UniversalParser
          config:
            # CHUNKING SETTINGS - Adjust these to control chunk size
            chunk_size: 1000        # Target characters per chunk
            chunk_overlap: 200      # Overlap between chunks for context

            # CHUNKING STRATEGY - Options:
            #   semantic   - AI-based boundaries (best for mixed content)
            #   sections   - Split on headers (best for structured docs)
            #   paragraphs - Split on blank lines (best for prose)
            #   sentences  - Split on sentences (best for dense text)
            #   characters - Fixed size (fallback)
            chunk_strategy: sections

            # OCR SETTINGS - For scanned documents and images
            use_ocr: true
            # ocr_endpoint: http://127.0.0.1:14345/v1/vision/ocr

      extractors:
        - type: UniversalExtractor
          config:
            # KEYWORD EXTRACTION
            keyword_count: 5        # Keywords per chunk (1-50)

            # SUMMARY GENERATION
            generate_summary: true
            summary_sentences: 2    # Sentences in summary (1-10)

            # ENTITY EXTRACTION (slower but useful)
            extract_entities: false  # Set true for people, orgs, places

            # LANGUAGE DETECTION
            detect_language: true
